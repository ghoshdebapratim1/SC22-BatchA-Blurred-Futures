{"backend_state":"running","connection_file":"/projects/820ea3ac-497c-43fd-9cb7-abe34292faa8/.local/share/jupyter/runtime/kernel-a7d21dad-21bf-4275-a156-0d9e4a0882fd.json","kernel":"nlp_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Seq2Seq en-cn.ipynb","provenance":[]},"interpreter":{"hash":"335ee12212264728feb72f243af72c5a8ea26c832f07e1f651ce9e17c7ceae23"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1655237258600,"exec_count":2,"id":"dcdddd","input":"import numpy as np\nimport torch.nn as nn\nfrom nltk.tokenize import WordPunctTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport pandas as pd\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfrom Word2Sequence import Word2Sequence\nfrom Dataset import Dataset\nfrom Seq2Seq import Seq2Seq","kernel":"nlp_env","metadata":{"id":"PS0kPzE04YFO"},"pos":2,"start":1655237258594,"state":"done","type":"cell"}
{"cell_type":"code","end":1655237283506,"exec_count":4,"id":"056e78","input":"# read small_en-cn.txt file\ndata_path = './eng-chin.txt'\ndf = pd.read_table(data_path,header=None).iloc[:,:]\ndf = df.drop([2],axis=1)\ndf.columns=['english','chinese']\n\ninput_texts = df.english.values.tolist() #this will be all of the english sentences\ntarget_texts = df.chinese.values.tolist() #this will be all of the chinese sentences","kernel":"nlp_env","pos":3,"start":1655237283501,"state":"done","type":"cell"}
{"cell_type":"code","end":1655237501737,"exec_count":16,"id":"be4751","input":"'''\nYour code here: Try printing some english and chinese sentences from their lists input_texts and target_texts!\n'''\n# print(input_texts[:10])\n# target_texts[:10]","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'\\nYour code here: Try printing some english and chinese sentences from their lists input_texts and target_texts!\\n'"},"exec_count":16}},"pos":4,"start":1655237501727,"state":"done","type":"cell"}
{"cell_type":"code","end":1655237778690,"exec_count":18,"id":"c22056","input":"'''\nYour code here: Explore this data. Can you calculate the maximum length of a sequence in each dataset english and chinese?\n'''\nmax_english_length = 0\nfor sentence in english:\n    if len(sentence) > max_english_length:\n        max_english_length = len(sentence)\n\nmax_chinese_length = 0\nfor sentence in chinese:\n    if len(sentence) > max_chinese_length:\n        max_chinese_length = len(sentence)\n\nprint(max_english_length)\nprint(max_chinese_length)\n# calculate max_len of any sequence in 'chinese' list and save it to a variable called max_chinese_length","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"25\n39\n"}},"pos":6,"start":1655237778679,"state":"done","type":"cell"}
{"cell_type":"code","end":1655238217473,"exec_count":31,"id":"dc1179","input":"input_tokenizer = Word2Sequence()\nfor words in english:\n    input_tokenizer.fit(words)\ninput_tokenizer.build_vocab(min=1, max_features=None) #inpu\n\noutput_tokenizer = Word2Sequence()\nfor words in chinese:\n    output_tokenizer.fit(words)\noutput_tokenizer.build_vocab(min=1, max_features=None)\n\n'''\nYour code here: print the total english words in your input tokenizer and total chinese words in your output tokenizer below!\n'''\ntotal_eng_words = len(input_tokenizer)\ntotal_chin_words = len(output_tokenizer)\nprint(total_eng_words)\nprint(total_chin_words)","kernel":"nlp_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzoUqCrq4fWj","outputId":"4290ee15-457e-44d7-f083-f12a2e5d78a2"},"output":{"0":{"name":"stdout","text":"199\n317\n"}},"pos":7,"start":1655238217407,"state":"done","type":"cell"}
{"cell_type":"code","end":1655238226972,"exec_count":32,"id":"5dad49","input":"# Seq2Seq Parameters\nin_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\nout_maxlen = max_chinese_length + 1 # 39 + 1(<EOS> token or <SOS> token)\nn_hidden = 32 # number of \"neurons\" per layer\nd_model = 64 # number of embedding dimensions to represent each word\nenc_n_class = len(input_tokenizer.dict) # OR... vocab size of englisth -> 199\ndec_n_class = len(output_tokenizer.dict) # OR... vocab size of chinese -> 317\nbatch_size = 1","kernel":"nlp_env","metadata":{"id":"qm_Qhnlk49Rn"},"pos":9,"start":1655238226964,"state":"done","type":"cell"}
{"cell_type":"code","end":1655238237003,"exec_count":33,"id":"1057cc","input":"eng_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\nchin_maxlen = max_chinese_length + 1  # 39 + 1(<EOS> token or <SOS> token)\nbatch_size = 1 \n\n# Setup the Dataset.\ndataset = Dataset(\n    X = english,\n    Y = chinese,\n    in_tknz = input_tokenizer, out_tknz = output_tokenizer,\n    in_maxlen = eng_maxlen, out_maxlen = chin_maxlen\n)\n\n'''\nThe following are helper functions to help pytorch. You won't need to know this much.\n'''\n# NOTE: collate_fn preprocesses your input from PyTorch Dataset above during PyTorch DataLoader\ndef collate_fn(batch):\n    '''\n    param batch: ([enc_in, dec_in, dec_out]， [enc_in, dec_in, dec_out], output of getitem...)\n    '''\n    # unpack values\n    enc_in, dec_in, dec_out = list(zip(*batch))\n    # Return tensor type\n    return torch.LongTensor(enc_in), torch.LongTensor(dec_in), torch.LongTensor(dec_out)\n\ndef get_dataloader(dataset, batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn):\n    '''\n    Returns a way to access and use the data\n    '''\n    dataloader = DataLoader(dataset=dataset,\n                            batch_size=batch_size,\n                            shuffle=shuffle,\n                            drop_last=drop_last,\n                            collate_fn=collate_fn)\n    return dataloader\n# Get PyTorch DataLoader\ndataloader = get_dataloader(dataset, batch_size)\ndataloader = get_dataloader(dataset, batch_size)","kernel":"nlp_env","pos":10,"start":1655238237001,"state":"done","type":"cell"}
{"cell_type":"code","end":1655238258094,"exec_count":34,"id":"0fc50a","input":"model = Seq2Seq(\n    in_maxlen = in_maxlen,\n    out_maxlen = out_maxlen,\n    n_hidden = n_hidden,\n    enc_n_class = len(input_tokenizer.dict),\n    dec_n_class = len(output_tokenizer.dict),\n    d_model = d_model,\n    num_layers = 1,\n)\nmodel.to(device)\n# # If you have saved a model before\n# model.load_state_dict(torch.load(\"seq2seq.pt\", map_location=device))","kernel":"nlp_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVVbVP7l5AJg","outputId":"e28da9fa-5fa2-4fbd-b4d3-49de9999475b"},"output":{"0":{"name":"stderr","text":"/projects/820ea3ac-497c-43fd-9cb7-abe34292faa8/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n  warnings.warn(\"dropout option adds dropout after all but last \"\n"},"1":{"data":{"text/plain":"Seq2Seq(\n  (encoder): GRU(64, 32, dropout=0.3)\n  (decoder): GRU(64, 32, dropout=0.3)\n  (embed_enc): Embedding(199, 64)\n  (embed_dec): Embedding(317, 64)\n  (fc): Linear(in_features=32, out_features=317, bias=True)\n)"},"exec_count":34}},"pos":11,"start":1655238258079,"state":"done","type":"cell"}
{"cell_type":"code","end":1655238265350,"exec_count":35,"id":"170255","input":"# Define Loss and Optimizer -- these are ways we define performance for our model. If you're curious: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\ncriterion = nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=1e-2)","kernel":"nlp_env","metadata":{"id":"PtNvjmBo5A8W"},"pos":12,"start":1655238265334,"state":"done","type":"cell"}
{"cell_type":"code","end":1655239534211,"exec_count":55,"id":"388ec8","input":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\n%matplotlib inline\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points): # Helper function for showing our plots\n    plt.figure()\n    fig, ax = plt.subplots()\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","kernel":"nlp_env","metadata":{"id":"DCWlner5CkY-"},"pos":16,"start":1655239534201,"state":"done","type":"cell"}
{"cell_type":"code","end":1655239539006,"exec_count":56,"id":"febb52","input":"showPlot([loss.cpu().item() for loss in loss_records])","kernel":"nlp_env","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":720},"id":"WGjbNIopCkzd","outputId":"dc2375cb-efe2-4756-dd01-309e4f056e1a"},"output":{"0":{"data":{"text/plain":"<Figure size 432x288 with 0 Axes>"}},"1":{"data":{"image/png":"27a2ac1414f2a192ead6009a289b54bea4316f8b","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":17,"start":1655239537119,"state":"done","type":"cell"}
{"cell_type":"code","end":1655239548479,"exec_count":57,"id":"3992cb","input":"'''\nNo need to touch this code: \n'''\n\ndef translate(eng_sent, model, device):\n    # set up the inputs and variables\n    model.eval()\n    model.to(device)\n    eng_sent = tk.tokenize(eng_sent.lower()) + [\"<EOS>\"]\n    eng_sent = input_tokenizer.transform(eng_sent, max_len=in_maxlen, pad_first=False)\n    dec_in = ([\"<SOS>\"] + [\"<PAD>\"]*out_maxlen)[:out_maxlen]\n    dec_in = output_tokenizer.transform(dec_in, max_len=out_maxlen, pad_first=False)\n    \n    enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n    eng_sent, dec_in = torch.LongTensor(eng_sent), torch.LongTensor(dec_in)\n\n    eng_sent = eng_sent.unsqueeze(0)\n    dec_in = dec_in.unsqueeze(0)\n    eng_sent, dec_in = eng_sent.to(device), dec_in.to(device)\n\n    # run the model\n    with torch.no_grad():\n        # eng_sent: [1(b), 26(in_maxlen)]\n        embedded_X = model.embed_enc(eng_sent)\n        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n        embedded_X = embedded_X.permute(1, 0, 2)\n        _, memory = model.encoder(embedded_X, enc_h_0)\n        pred_loc = 0\n        for i in range(out_maxlen-1):\n            embedded_Y = model.embed_dec(dec_in)\n            embedded_Y = embedded_Y.permute(1, 0, 2)\n            outputs, _ = model.decoder(embedded_Y, memory)\n            outputs = outputs.permute(1, 0, 2)\n            pred = model.fc(outputs)\n            pred = pred[0][pred_loc].topk(1)[1].item()\n            pred_loc += 1\n            if pred == 2:\n                dec_in[0][pred_loc] = pred\n                break\n            else:\n                dec_in[0][pred_loc] = pred\n    return dec_in","kernel":"nlp_env","metadata":{"id":"XHs9IRJK8usV"},"pos":19,"start":1655239548475,"state":"done","type":"cell"}
{"cell_type":"code","end":1655240053296,"exec_count":69,"id":"b53b77","input":"'''\nYour code here: change the number of epochs to see how it effects training time and quality\n'''\nepochs = 50\n\n\n'''\nTraining -- no need to touch the code below.\n'''\ntorch.cuda.empty_cache()\nmodel.train()\nmodel.to(device)\nloss_records = []\n\n\nfor epoch in range(epochs):\n    # runs the model and calculates loss\n    loss = 0\n    for _, (enc_in, dec_in, dec_out) in enumerate(dataloader):\n        # enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\n        enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n        # To Cuda Device if available\n        enc_in, dec_in = enc_in.to(device), dec_in.to(device)\n        \n        pred = model(enc_in, enc_h_0, dec_in)\n        \n        dec_out = dec_out.to(device)\n        for i in range(len(dec_out)): # dec_in.shape: [1(b), 40(out_maxlen)]\n            # pred[i].shape: [40(out_maxlen), 317(dec_n_class)]\n            # dec_out[i].shape: [40(out_maxlen)]\n            loss += criterion(pred[i], dec_out[i])\n\n    if (epoch) % 10 == 0:\n        print(f\"Epoch: {epoch}, Loss: {loss}\")\n\n    if (epoch) % 100 == 0:\n        loss_records.append(loss)\n    \n    # runs the actual back propacation\n    optim.zero_grad()\n    loss.backward()\n    optim.step()\n    torch.save(model.state_dict(), \"seq2seq.pt\")\n    ","kernel":"nlp_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTSlF8fk5QpG","outputId":"3eb0df28-80b9-452b-e9b5-5c7ffff27c98"},"output":{"0":{"name":"stdout","text":"Epoch: 0, Loss: 2.817699432373047\n"},"1":{"name":"stdout","text":"Epoch: 10, Loss: 2.6659324169158936\n"},"2":{"ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# runs the actual back propacation\u001b[39;00m\n\u001b[1;32m     40\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq2seq.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}},"pos":14,"start":1655240031605,"state":"done","type":"cell"}
{"cell_type":"code","end":1655240468079,"exec_count":85,"id":"b8370c","input":"'''\nYour code here: translate custom sentences using the code above. Hint: You won't need a for loop!\n'''\ncustom_sentence = \"the tree has leaves\"\ndef translate_english_to_chinese(sent):\n    translated = translate(sent, model, torch.device(\"cpu\"))\n    translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n    translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\" and word != '<UNK>'])\n    print(f\"{sent} -> \\n{translated_sent}\")\ntranslate_english_to_chinese(custom_sentence)\n\n","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"the tree has leaves -> \n我为自己买了羽毛球，但我忘记买羽毛球了。\n"}},"pos":23,"scrolled":false,"start":1655240468024,"state":"done","type":"cell"}
{"cell_type":"code","end":1655241016669,"exec_count":90,"id":"dd3126","input":"#read in our model object. Tokenize our data\ntk = WordPunctTokenizer()\nenglish = [tk.tokenize(sentence.lower()) for sentence in input_texts]\nchinese = [[x for x in sentence] for sentence in target_texts]","kernel":"nlp_env","metadata":{"id":"cPXhq9PO4dOC"},"pos":5,"start":1655241016660,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":89,"id":"7d9f3d","input":"import random\n# eng_sents = random.sample(input_texts, 5)\n\n# for sent in eng_sents:\n#   translated = translate(sent, model, torch.device(\"cpu\"))\n#   translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n#   translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\" and word != '<UNK>'])\n#   print(f\"{sent} -> \\n{translated_sent}\")\n    ","kernel":"nlp_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fh0-iZdvBUFF","outputId":"f42cb9ed-a961-4d0f-c94c-6be4fb8d6656"},"output":{"0":{"name":"stdout","text":"['Does any other country fan the flames of patriotism as much as America?', 'I always enjoy listening to classical music when I have some free time.', 'I was nine years old when I asked my mom if Santa Claus really existed.', \"I'm a foreigner and I don't know Czech very well. Please, speak slowly.\", \"If it's at all possible, I'd like you to take part in the next meeting.\", 'If you enjoy the work you do, you have something worth more than money.', \"It was not until I had a baby myself that I knew what mother's love is.\", 'Kindness is the language which the deaf can hear and the blind can see.', 'Mary came home from school in tears because her friends had teased her.', 'My father was no less affectionate and tender to me than my mother was.', \"Now's the time to decide whether you really want to get married or not.\", 'People show up bright on an infrared camera because of their body heat.', 'The police have been searching for the stolen goods for almost a month.', 'They told me that I would feel a little better if I took this medicine.', \"Tom couldn't go to college because his family didn't have enough money.\", 'When his food supply ran short, he had to look for a new place to live.', 'While I was reading in bed last night, I fell asleep with the light on.', 'Where have you been? \"I have been to the station to see a friend off.\"', \"By the way, did you find the umbrella you said you'd lost the other day?\", 'Her eyes shone with joy when she saw that her mother was not mad at her.', 'I can place the palms of my hands on the floor without bending my knees.', \"I learned to drive a car and got a driver's license when I was eighteen.\", \"I learned to drive a car when I was eighteen and got a driver's license.\", 'I was planning on going to the beach today, but then it started to rain.', \"If we knew what we were doing, it wouldn't be called research, would it?\", \"If you want to go, then go. If you don't want to, then it's no big deal.\", 'In the U.S., most people can vote when they reach eighteen years of age.', 'It is the things that we do not possess which seem to us most desirable.', \"Rather than cutting down on cigarettes, why don't you just give them up?\", 'Sociopaths rarely display remorse or feelings of guilt for their crimes.', \"Tom can't account for his whereabouts on the day that Mary was murdered.\", 'Tom never forgets to give his wife flowers on their wedding anniversary.', 'Tom was able to make himself understood in French when he visited Paris.', \"We were talking about something at that time, but I don't remember what.\", \"You shouldn't share too much private information on the social networks.\", 'After Tom lost his job, he started to gamble to cope with his depression.', 'After school, I go to an English school to practice English conversation.', \"I think you'll have very little difficulty in getting a driver's license.\", 'I thought we had found the perfect hiding place, but the police found us.', \"I'd like to know the phone number of the nearest American Express office.\", 'She visits the dentist on a regular basis, so she seldom gets toothaches.', \"To make matters worse, he isn't even conscious of annoying his neighbors.\", 'You seem to be prejudiced against ideas that come from foreign countries.', 'If a sick person folds one thousand paper cranes, her wish will come true.', \"It's hard to believe that Tom wasn't aware that Mary was in love with him.\", 'Tom returned to his hometown to visit his parents during the summer break.', 'We must take into account the wishes of all the family in planning a trip.', \"You're much less likely to get a good position if you don't speak English.\", 'After asking for my key at the front desk, I took the elevator to my floor.', 'English has now become the common language of several nations in the world.', 'Outside the school, she saw people with no homes living in cardboard boxes.', \"The Prime Minister's speech was calculated to anger the opposition parties.\", \"The good thing about this electronic dictionary is that it's easy to carry.\", 'The lady really flipped out when she learned she had won a million dollars.', 'We apologize for the delay and regret any inconvenience it may have caused.', 'According to newspaper reports, there was an airplane accident last evening.', 'After he had graduated from the university, he taught English for two years.', 'If a man had 11 sheep and all but 9 died, how many sheep would he have left?', 'If it rains on that day, the game will be postponed until the next fine day.', \"It would take me too much time to explain to you why it's not going to work.\", 'The importation of rare wild animals to this country is strictly prohibited.', 'The statue of Hachiko, the faithful dog, stands in front of Shibuya Station.', 'A person views things differently according to whether they are rich or poor.', 'Although the government refuses to admit it, its economic policy is in ruins.', 'Mary tied an apron around her waist and then took the turkey out of the oven.', 'People look at things differently depending on whether they are rich or poor.', 'The population of London is much greater than that of any other British city.', \"They consider it impolite to disagree with someone they don't know very well.\", 'Three out of four Americans believe in the existence of paranormal phenomena.', \"Tom came to the conclusion that no matter what he did, Mary wouldn't like it.\", 'Eighty percent of all information on computers around the world is in English.', 'I thought that we had found the perfect hiding place, but the police found us.', \"I've had a scratchy throat since this morning. I wonder if I've caught a cold.\", \"If it looks like an apple and it tastes like an apple, it's probably an apple.\", 'The world is just like a book, and every step you take is like turning a page.', \"Today, I was supposed to study at the library but I woke up around 12 o'clock.\", 'Tom can write almost like a native speaker, but his pronunciation is terrible.', \"Tom did the best he could, but he wasn't able to get a higher grade than Mary.\", 'As the train came to a halt, all of the passengers wondered what was happening.', 'Charles Lindbergh made the first solo flight across the Atlantic Ocean in 1927.', \"His scores are always better than mine, even though he doesn't study very much.\", \"I don't have a lot of work, but it's enough to keep me in the office this week.\", 'I returned the books I borrowed from the library, and I borrowed some new ones.', \"Publication of the article was timed to coincide with the professor's birthday.\", \"She's popular, not because she's beautiful, but because she's kind to everyone.\", 'The telephone operator asked the caller to hold on until a connection was made.', \"Whoever said money can't buy happiness simply didn't know where to go shopping.\", 'At the time there were no native English speakers teaching in any public school.', 'Rio de Janeiro is perfectly safe as long as you stay out of the dangerous areas.', 'She was asked to convince him to get his son or someone else to paint the house.', 'Tom always speaks in such a low voice that I can barely understand what he says.', \"Even though I studied English for 6 years in school, I'm not good at speaking it.\", 'I bought a second badminton racket for myself, but I forgot to buy a shuttlecock.', \"I didn't know the city, and what's more, I couldn't speak a word of the language.\", 'The ages of the two children put together was equivalent to that of their father.', 'To the man who only has a hammer in the toolkit, every problem looks like a nail.', 'Tom went swimming in the river, but when he got out, his clothes had been stolen.', 'Being a good conversationalist does not just mean being a good speaker of English.', \"Manholes are round because that way they won't accidentally fall through the hole.\"]\n"}},"pos":21,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"2202cf","input":"# Using our Model in Practice\n\nCheck out these examples below. This is how you can translate sequences!\n\n","metadata":{"id":"kG_fTQzoBsMu"},"pos":20,"type":"cell"}
{"cell_type":"markdown","id":"35a3e6","input":"## Let's check out our model's progress\nNo need to change the code below, this will plot our loss over time. How do you think we can tweak our code to decrease loss even further?","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"362bea","input":"<h1>Training our model</h1>","metadata":{"id":"wVpmLnAtBLEV"},"pos":13,"type":"cell"}
{"cell_type":"markdown","id":"55a70f","input":"## Preparing the data\nWe need to import our packages and data to learn a little bit about the problem at hand.","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"5eda00","input":"<h1>Code for Translating with our Model</h1>\nThis is where the Seq2Seq happens after the model is trained.\n","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"621c85","input":"# The Task at Hand\n\nHave you ever wondered if computers could translate languages? Did you think google translate or duolingo worked because they memorized answers? \n\nThe type of problem that translation solves is sequence to sequence. For instance, we could convert an english input sequence to a german output sequence. \n\nIn this activity, we will create an english -> chinese translator and apply what we've been learning about LSTMs & RNNs.","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"729c9e","input":"<h1>Creating the model</h1>\n\n![image.png](data:image/png;base64,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)\n\nNOTE: For Structure of Encoder Inputs, they can all be either (assume all have same maxlen): \n1. \\<SOS>, word1, word2, word3, ..., \\<EOS>\n2. word1, word2, word3, ..., \\<EOS> \n3. word1, word2, word3, ...\n\nNOTE: But Decoder In and Out structures should always look like this (assume all have same maxlen):\n- Decoder Input: \\<SOS>, word1, word2, word3, ...\n- Decoder Output: word1, word2, word3, ..., \\<EOS>  \n\nThis means that our input and ouput max length should be one more than the sequence's max length.\n\nWHY? Data Structure:\n- 1. Encoder Input: [word1, word2, ... + <EOS>]\n- 2. Decoder Input: [<SOS> + word1, word2, ...]\n- 3. Decoder Output:[word1, word2, ... + <EOS>]\n    \nnn docs - https://pytorch.org/docs/stable/nn.html","pos":8,"type":"cell"}
{"cell_type":"markdown","id":"e14705","input":"# Your turn!\nCan you use the code in the cell above to translate custom sentences? ","pos":22,"type":"cell"}
{"end":1655237503857,"exec_count":17,"id":"750434","input":"print(chinese[:10])","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"[['有', '没', '有', '一', '个', '国', '家', '比', '美', '国', '更', '提', '倡', '爱', '国', '主', '义', '？'], ['有', '空', '的', '时', '候', '，', '我', '总', '喜', '欢', '听', '古', '典', '音', '乐', '。'], ['我', '九', '岁', '的', '时', '候', '问', '我', '妈', '妈', '圣', '诞', '老', '人', '是', '否', '真', '的', '存', '在', '。'], ['我', '是', '外', '国', '人', '，', '我', '捷', '克', '语', '不', '好', '，', '请', '说', '慢', '一', '点', '。'], ['如', '果', '可', '能', '的', '話', ',', ' ', '我', '希', '望', '你', '參', '加', '下', '一', '次', '的', '會', '議', '。'], ['如', '果', '你', '喜', '歡', '你', '做', '的', '工', '作', '，', '你', '就', '有', '比', '金', '錢', '更', '有', '價', '值', '的', '東', '西', '。'], ['直', '到', '我', '自', '己', '有', '了', '孩', '子', '我', '才', '明', '白', '了', '什', '么', '是', '母', '爱', '。'], ['善', '良', '是', '聾', '子', '能', '聽', '盲', '人', '能', '看', '的', '語', '言', '。'], ['玛', '丽', '哭', '着', '从', '学', '校', '跑', '回', '了', '家', '里', '，', '因', '为', '她', '的', '朋', '友', '捉', '弄', '了', '她', '。'], ['我', '爸', '爸', '对', '我', '的', '爱', '和', '照', '顾', '不', '比', '我', '妈', '妈', '少', '。']]\n"}},"pos":5.5,"start":1655237503845,"state":"done","type":"cell"}
{"id":"027182","input":"","pos":7.25,"type":"cell"}
{"id":"03571e","input":"","pos":21.125,"type":"cell"}
{"id":"29f76a","input":"","pos":23.25,"type":"cell"}
{"id":"2f1b81","input":"","pos":14.0625,"type":"cell"}
{"id":"2f8375","input":"","pos":21.03125,"type":"cell"}
{"id":"311772","input":"","pos":5.25,"type":"cell"}
{"id":"346192","input":"","pos":7.5,"type":"cell"}
{"id":"35537a","input":"","pos":21.25,"type":"cell"}
{"id":"38dced","input":"","pos":19.5,"type":"cell"}
{"id":"3dd24f","input":"","pos":23.00390625,"type":"cell"}
{"id":"3f0d52","input":"","pos":14.25,"type":"cell"}
{"id":"402df1","input":"","pos":21.0625,"type":"cell"}
{"id":"444504","input":"","pos":24,"type":"cell"}
{"id":"456d81","input":"","pos":21.00390625,"type":"cell"}
{"id":"45a861","input":"","pos":7.125,"type":"cell"}
{"id":"4a4655","input":"","pos":23.0625,"type":"cell"}
{"id":"54df2e","input":"","pos":14.5,"type":"cell"}
{"id":"6216ce","input":"","pos":16.5,"type":"cell"}
{"id":"69188d","input":"","pos":21.0078125,"type":"cell"}
{"id":"7c1283","input":"","pos":21.5,"type":"cell"}
{"id":"7e6042","input":"","pos":4.5,"type":"cell"}
{"id":"8c4424","input":"","pos":5.75,"type":"cell"}
{"id":"909092","input":"","pos":21.001953125,"type":"cell"}
{"id":"9b97c1","input":"","pos":17.25,"type":"cell"}
{"id":"a6045b","input":"","pos":23.0078125,"type":"cell"}
{"id":"afe941","input":"","pos":23.015625,"type":"cell"}
{"id":"c2288b","input":"","pos":21.015625,"type":"cell"}
{"id":"c4e77f","input":"","pos":23.03125,"type":"cell"}
{"id":"c767e2","input":"","pos":17.5,"type":"cell"}
{"id":"e10b5f","input":"","pos":23.5,"type":"cell"}
{"id":"e95c8c","input":"","pos":16.25,"type":"cell"}
{"id":"f06269","input":"","pos":23.125,"type":"cell"}
{"id":"f64708","input":"","pos":14.125,"type":"cell"}
{"id":0,"time":1655237254192,"type":"user"}
{"last_load":1655237077957,"type":"file"}