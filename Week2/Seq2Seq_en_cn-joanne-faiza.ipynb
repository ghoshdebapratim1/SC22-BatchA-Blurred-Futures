{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Task at Hand\n",
    "\n",
    "Have you ever wondered if computers could translate languages? Did you think google translate or duolingo worked because they memorized answers? \n",
    "\n",
    "The type of problem that translation solves is sequence to sequence. For instance, we could convert an english input sequence to a german output sequence. \n",
    "\n",
    "In this activity, we will create an english -> chinese translator and apply what we've been learning about LSTMs & RNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Preparing the data\n",
    "We need to import our packages and data to learn a little bit about the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "PS0kPzE04YFO"
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from Word2Sequence import Word2Sequence\n",
    "from Dataset import Dataset\n",
    "from Seq2Seq import Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "# read small_en-cn.txt file\n",
    "data_path = './eng-chin.txt'\n",
    "df = pd.read_table(data_path,header=None).iloc[:,:]\n",
    "df = df.drop([2],axis=1)\n",
    "df.columns=['english','chinese']\n",
    "\n",
    "input_texts = df.english.values.tolist() #this will be all of the english sentences\n",
    "target_texts = df.chinese.values.tolist() #this will be all of the chinese sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does any other country fan the flames of patriotism as much as America?\n",
      "有没有一个国家比美国更提倡爱国主义？\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Try printing some english and chinese sentences from their lists input_texts and target_texts!\n",
    "'''\n",
    "\n",
    "\n",
    "print(input_texts[0])\n",
    "print(target_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "id": "cPXhq9PO4dOC"
   },
   "outputs": [
   ],
   "source": [
    "#read in our model object. Tokenize our data\n",
    "tk = WordPunctTokenizer()\n",
    "english = [tk.tokenize(sentence.lower()) for sentence in input_texts]\n",
    "chinese = [[x for x in sentence] for sentence in target_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: Explore this data. Can you calculate the maximum length of a sequence in each dataset english and chinese?\n",
    "'''\n",
    "\n",
    "# calculate max_len of any sequence in 'english' list and save it to a variable called max_english_length \n",
    "\n",
    "max_english_length = 0\n",
    "\n",
    "for i in range(len(english)):\n",
    "    if len(english[i]) > max_english_length:\n",
    "        max_english_length = len(english[i])\n",
    "print(max_english_length)\n",
    "# calculate max_len of any sequence in 'chinese' list and save it to a variable called max_chinese_length\n",
    "max_chinese_length = 0\n",
    "\n",
    "for i in range(len(chinese)):\n",
    "    if len(chinese[i]) > max_chinese_length:\n",
    "        max_chinese_length = len(chinese[i])\n",
    "print(max_chinese_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "ZzoUqCrq4fWj",
    "outputId": "4290ee15-457e-44d7-f083-f12a2e5d78a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Word2Sequence()\n",
    "for words in english:\n",
    "    input_tokenizer.fit(words)\n",
    "input_tokenizer.build_vocab(min=1, max_features=None) #inpu\n",
    "\n",
    "output_tokenizer = Word2Sequence()\n",
    "for words in chinese:\n",
    "    output_tokenizer.fit(words)\n",
    "output_tokenizer.build_vocab(min=1, max_features=None)\n",
    "\n",
    "'''\n",
    "Your code here: print the total english words in your input tokenizer and total chinese words in your output tokenizer below!\n",
    "'''\n",
    "\n",
    "print(len(input_tokenizer))\n",
    "print(len(output_tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Creating the model</h1>\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "NOTE: For Structure of Encoder Inputs, they can all be either (assume all have same maxlen): \n",
    "\n",
    "1. \\<SOS>, word1, word2, word3, ..., \\<EOS>\n",
    "2. word1, word2, word3, ..., \\<EOS> \n",
    "3. word1, word2, word3, ...\n",
    "\n",
    "NOTE: But Decoder In and Out structures should always look like this (assume all have same maxlen):\n",
    "\n",
    "- Decoder Input: \\<SOS>, word1, word2, word3, ...\n",
    "- Decoder Output: word1, word2, word3, ..., \\<EOS>  \n",
    "\n",
    "This means that our input and ouput max length should be one more than the sequence's max length.\n",
    "\n",
    "WHY? Data Structure:\n",
    "\n",
    "- 1. Encoder Input: [word1, word2, ... + <EOS>]\n",
    "- 2. Decoder Input: [<SOS> + word1, word2, ...]\n",
    "- 3. Decoder Output:[word1, word2, ... + <EOS>]\n",
    "    \n",
    "\n",
    "nn docs - https://pytorch.org/docs/stable/nn.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "id": "qm_Qhnlk49Rn"
   },
   "outputs": [
   ],
   "source": [
    "# Seq2Seq Parameters\n",
    "in_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\n",
    "out_maxlen = max_chinese_length + 1 # 39 + 1(<EOS> token or <SOS> token)\n",
    "n_hidden = 32 # number of \"neurons\" per layer\n",
    "d_model = 64 # number of embedding dimensions to represent each word\n",
    "enc_n_class = len(input_tokenizer.dict) # OR... vocab size of englisth -> 199\n",
    "dec_n_class = len(output_tokenizer.dict) # OR... vocab size of chinese -> 317\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "eng_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\n",
    "chin_maxlen = max_chinese_length + 1  # 39 + 1(<EOS> token or <SOS> token)\n",
    "batch_size = 1 \n",
    "\n",
    "# Setup the Dataset.\n",
    "dataset = Dataset(\n",
    "    X = english,\n",
    "    Y = chinese,\n",
    "    in_tknz = input_tokenizer, out_tknz = output_tokenizer,\n",
    "    in_maxlen = eng_maxlen, out_maxlen = chin_maxlen\n",
    ")\n",
    "\n",
    "'''\n",
    "The following are helper functions to help pytorch. You won't need to know this much.\n",
    "'''\n",
    "# NOTE: collate_fn preprocesses your input from PyTorch Dataset above during PyTorch DataLoader\n",
    "def collate_fn(batch):\n",
    "    '''\n",
    "    param batch: ([enc_in, dec_in, dec_out]， [enc_in, dec_in, dec_out], output of getitem...)\n",
    "    '''\n",
    "    # unpack values\n",
    "    enc_in, dec_in, dec_out = list(zip(*batch))\n",
    "    # Return tensor type\n",
    "    return torch.LongTensor(enc_in), torch.LongTensor(dec_in), torch.LongTensor(dec_out)\n",
    "\n",
    "def get_dataloader(dataset, batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn):\n",
    "    '''\n",
    "    Returns a way to access and use the data\n",
    "    '''\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            drop_last=drop_last,\n",
    "                            collate_fn=collate_fn)\n",
    "    return dataloader\n",
    "# Get PyTorch DataLoader\n",
    "dataloader = get_dataloader(dataset, batch_size)\n",
    "dataloader = get_dataloader(dataset, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "oVVbVP7l5AJg",
    "outputId": "e28da9fa-5fa2-4fbd-b4d3-49de9999475b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/820ea3ac-497c-43fd-9cb7-abe34292faa8/miniconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): GRU(64, 32, dropout=0.3)\n",
       "  (decoder): GRU(64, 32, dropout=0.3)\n",
       "  (embed_enc): Embedding(199, 64)\n",
       "  (embed_dec): Embedding(317, 64)\n",
       "  (fc): Linear(in_features=32, out_features=317, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Seq2Seq(\n",
    "    in_maxlen = in_maxlen,\n",
    "    out_maxlen = out_maxlen,\n",
    "    n_hidden = n_hidden,\n",
    "    enc_n_class = len(input_tokenizer.dict),\n",
    "    dec_n_class = len(output_tokenizer.dict),\n",
    "    d_model = d_model,\n",
    "    num_layers = 1,\n",
    ")\n",
    "model.to(device)\n",
    "# # If you have saved a model before\n",
    "# model.load_state_dict(torch.load(\"seq2seq.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "id": "PtNvjmBo5A8W"
   },
   "outputs": [
   ],
   "source": [
    "# Define Loss and Optimizer -- these are ways we define performance for our model. If you're curious: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "wVpmLnAtBLEV"
   },
   "source": [
    "<h1>Training our model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "PTSlF8fk5QpG",
    "outputId": "3eb0df28-80b9-452b-e9b5-5c7ffff27c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 15.76434326171875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# runs the model and calculates loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, (enc_in, dec_in, dec_out) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;66;03m# enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         enc_h_0 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minit_enc_hidden_GRU(batch_size, device)\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# To Cuda Device if available\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 530\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:569\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 569\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    570\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter._next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_index\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py:226\u001b[0m, in \u001b[0;36mBatchSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[List[\u001b[38;5;28mint\u001b[39m]]:\n\u001b[1;32m    225\u001b[0m     batch \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler:\n\u001b[1;32m    227\u001b[0m         batch\u001b[38;5;241m.\u001b[39mappend(idx)\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(batch) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/sampler.py:111\u001b[0m, in \u001b[0;36mRandomSampler.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mempty((), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mrandom_()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m--> 111\u001b[0m     generator \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     generator\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Your code here: change the number of epochs to see how it effects training time and quality \n",
    "'''\n",
    "epochs = 300\n",
    "\n",
    "\n",
    "'''\n",
    "Training -- no need to touch the code below.\n",
    "'''\n",
    "torch.cuda.empty_cache()\n",
    "model.train()\n",
    "model.to(device)\n",
    "loss_records = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # runs the model and calculates loss\n",
    "    loss = 0\n",
    "    for _, (enc_in, dec_in, dec_out) in enumerate(dataloader):\n",
    "        # enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\n",
    "        enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "        # To Cuda Device if available\n",
    "        enc_in, dec_in = enc_in.to(device), dec_in.to(device)\n",
    "        \n",
    "        pred = model(enc_in, enc_h_0, dec_in)\n",
    "        \n",
    "        dec_out = dec_out.to(device)\n",
    "        for i in range(len(dec_out)): # dec_in.shape: [1(b), 40(out_maxlen)]\n",
    "            # pred[i].shape: [40(out_maxlen), 317(dec_n_class)]\n",
    "            # dec_out[i].shape: [40(out_maxlen)]\n",
    "            loss += criterion(pred[i], dec_out[i])\n",
    "\n",
    "    if (epoch) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n",
    "    if (epoch) % 100 == 0:\n",
    "        loss_records.append(loss)\n",
    "    \n",
    "    # runs the actual back propacation\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    torch.save(model.state_dict(), \"seq2seq.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Let's check out our model's progress\n",
    "\n",
    "No need to change the code below, this will plot our loss over time. How do you think we can tweak our code to decrease loss even further?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "id": "DCWlner5CkY-"
   },
   "outputs": [
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points): # Helper function for showing our plots\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 720
    },
    "collapsed": false,
    "id": "WGjbNIopCkzd",
    "outputId": "dc2375cb-efe2-4756-dd01-309e4f056e1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 27,
     "metadata": {
     },
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Locator attempting to generate 2738 ticks ([51.6, ..., 599.0]), which exceeds Locator.MAXTICKS (1000).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showPlot([loss.cpu().item() for loss in loss_records])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<h1>Code for Translating with our Model</h1>\n",
    "This is where the Seq2Seq happens after the model is trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "id": "XHs9IRJK8usV"
   },
   "outputs": [
   ],
   "source": [
    "'''\n",
    "No need to touch this code: \n",
    "'''\n",
    "\n",
    "def translate(eng_sent, model, device):\n",
    "    # set up the inputs and variables\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    eng_sent = tk.tokenize(eng_sent.lower()) + [\"<EOS>\"]\n",
    "    eng_sent = input_tokenizer.transform(eng_sent, max_len=in_maxlen, pad_first=False)\n",
    "    dec_in = ([\"<SOS>\"] + [\"<PAD>\"]*out_maxlen)[:out_maxlen]\n",
    "    dec_in = output_tokenizer.transform(dec_in, max_len=out_maxlen, pad_first=False)\n",
    "    \n",
    "    enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n",
    "    eng_sent, dec_in = torch.LongTensor(eng_sent), torch.LongTensor(dec_in)\n",
    "\n",
    "    eng_sent = eng_sent.unsqueeze(0)\n",
    "    dec_in = dec_in.unsqueeze(0)\n",
    "    eng_sent, dec_in = eng_sent.to(device), dec_in.to(device)\n",
    "\n",
    "    # run the model\n",
    "    with torch.no_grad():\n",
    "        # eng_sent: [1(b), 26(in_maxlen)]\n",
    "        embedded_X = model.embed_enc(eng_sent)\n",
    "        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n",
    "        embedded_X = embedded_X.permute(1, 0, 2)\n",
    "        _, memory = model.encoder(embedded_X, enc_h_0)\n",
    "        pred_loc = 0\n",
    "        for i in range(out_maxlen-1):\n",
    "            embedded_Y = model.embed_dec(dec_in)\n",
    "            embedded_Y = embedded_Y.permute(1, 0, 2)\n",
    "            outputs, _ = model.decoder(embedded_Y, memory)\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "            pred = model.fc(outputs)\n",
    "            pred = pred[0][pred_loc].topk(1)[1].item()\n",
    "            pred_loc += 1\n",
    "            if pred == 2:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "                break\n",
    "            else:\n",
    "                dec_in[0][pred_loc] = pred\n",
    "    return dec_in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "kG_fTQzoBsMu"
   },
   "source": [
    "# Using our Model in Practice\n",
    "Check out these examples below. This is how you can translate sequences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": false,
    "id": "fh0-iZdvBUFF",
    "outputId": "f42cb9ed-a961-4d0f-c94c-6be4fb8d6656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom can write almost like a native speaker, but his pronunciation is terrible. -> \n",
      "<UNK><UNK><UNK><UNK><UNK>八公的<UNK><UNK>位。\n",
      "His scores are always better than mine, even though he doesn't study very much. -> \n",
      "他的分数总比我高，尽管他学习得少一点。\n",
      "I'd like to know the phone number of the nearest American Express office. -> \n",
      "我想知道最<UNK>的美國<UNK>通<UNK>事<UNK>的電話<UNK><UNK>。\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was not until I had a baby myself that I knew what mother's love is. -> \n",
      "直到我自己有了孩子我才明<UNK>了什么是母爱。\n",
      "Tom can't account for his whereabouts on the day that Mary was murdered. -> \n",
      "汤姆不能说明玛丽<UNK><UNK>那天自己在哪里。\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "eng_sents = random.sample(input_texts, 5)\n",
    "for sent in eng_sents:\n",
    "    translated = translate(sent, model, torch.device(\"cpu\"))\n",
    "    translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "    translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
    "    print(f\"{sent} -> \\n{translated_sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Your turn!\n",
    "Can you use the code in the cell above to translate custom sentences? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYour code here: translate custom sentences using the code above. Hint: You won't need a for loop!\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Your code here: translate custom sentences using the code above. Hint: You won't need a for loop!\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "cocalc": {
     "outputs": {
      "0": {
       "name": "input",
       "opts": {
        "password": false,
        "prompt": ""
       },
       "output_type": "stream",
       "value": "This is a sentence"
      }
     }
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " This is a sentence"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence -> \n",
      "如果一个人有11只羊，<UNK>了9只之外，其他全<UNK><UNK>了，那么他还<UNK>下几只羊<UNK>？\n"
     ]
    }
   ],
   "source": [
    "sent = input()\n",
    "translated = translate(sent, model, torch.device(\"cpu\"))\n",
    "translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n",
    "translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n",
    "print(f\"{sent} -> \\n{translated_sent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
   ],
   "name": "Seq2Seq en-cn.ipynb",
   "provenance": [
   ]
  },
  "interpreter": {
   "hash": "335ee12212264728feb72f243af72c5a8ea26c832f07e1f651ce9e17c7ceae23"
  },
  "kernelspec": {
   "display_name": "Python (nlp_env)",
   "language": "python",
   "metadata": {
    "debugger": true
   },
   "name": "nlp_env",
   "resource_dir": "/projects/820ea3ac-497c-43fd-9cb7-abe34292faa8/.local/share/jupyter/kernels/nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}