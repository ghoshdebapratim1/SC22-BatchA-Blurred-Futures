{"backend_state":"running","connection_file":"/projects/820ea3ac-497c-43fd-9cb7-abe34292faa8/.local/share/jupyter/runtime/kernel-81b6abd1-2a5b-48b6-822e-85fc6fbbc8f3.json","kernel":"nlp_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Seq2Seq en-cn.ipynb","provenance":[]},"interpreter":{"hash":"335ee12212264728feb72f243af72c5a8ea26c832f07e1f651ce9e17c7ceae23"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1655227527969,"exec_count":2,"id":"dcd299","input":"import numpy as np\nimport torch.nn as nn\nfrom nltk.tokenize import WordPunctTokenizer\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport pandas as pd\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfrom Word2Sequence import Word2Sequence\nfrom Dataset import Dataset\nfrom Seq2Seq import Seq2Seq","kernel":"nlp_env","metadata":{"id":"PS0kPzE04YFO"},"pos":2,"start":1655227526434,"state":"done","type":"cell"}
{"cell_type":"code","end":1655227530834,"exec_count":3,"id":"acbf6a","input":"# read small_en-cn.txt file\ndata_path = './eng-chin.txt'\ndf = pd.read_table(data_path,header=None).iloc[:,:]\ndf = df.drop([2],axis=1)\ndf.columns=['english','chinese']\n\ninput_texts = df.english.values.tolist() #this will be all of the english sentences\ntarget_texts = df.chinese.values.tolist() #this will be all of the chinese sentences","kernel":"nlp_env","pos":3,"start":1655227530813,"state":"done","type":"cell"}
{"cell_type":"code","end":1655227534272,"exec_count":4,"id":"461b0c","input":"#read in our model object. Tokenize our data\ntk = WordPunctTokenizer()\nenglish = [tk.tokenize(sentence.lower()) for sentence in input_texts]\nchinese = [[x for x in sentence] for sentence in target_texts]","kernel":"nlp_env","metadata":{"id":"cPXhq9PO4dOC"},"pos":5,"start":1655227534269,"state":"done","type":"cell"}
{"cell_type":"code","end":1655227726751,"exec_count":6,"id":"a930cf","input":"# Seq2Seq Parameters\nin_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\nout_maxlen = max_chinese_length + 1 # 39 + 1(<EOS> token or <SOS> token)\nn_hidden = 32 # number of \"neurons\" per layer\nd_model = 64 # number of embedding dimensions to represent each word\nenc_n_class = len(input_tokenizer.dict) # OR... vocab size of englisth -> 199\ndec_n_class = len(output_tokenizer.dict) # OR... vocab size of chinese -> 317\nbatch_size = 1","kernel":"nlp_env","metadata":{"id":"qm_Qhnlk49Rn"},"output":{"0":{"ename":"NameError","evalue":"name 'max_english_length' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Seq2Seq Parameters\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m in_maxlen \u001b[38;5;241m=\u001b[39m \u001b[43mmax_english_length\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# 25 + 1(<EOS> token)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m out_maxlen \u001b[38;5;241m=\u001b[39m max_chinese_length \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# 39 + 1(<EOS> token or <SOS> token)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m n_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m \u001b[38;5;66;03m# number of \"neurons\" per layer\u001b[39;00m\n","\u001b[0;31mNameError\u001b[0m: name 'max_english_length' is not defined"]}},"pos":9,"start":1655227726737,"state":"done","type":"cell"}
{"cell_type":"code","end":1655237715557,"exec_count":7,"id":"6c9510","input":"input_tokenizer = Word2Sequence()\nfor words in english:\n    input_tokenizer.fit(words)\ninput_tokenizer.build_vocab(min=1, max_features=None) #inpu\n\noutput_tokenizer = Word2Sequence()\nfor words in chinese:\n    output_tokenizer.fit(words)\noutput_tokenizer.build_vocab(min=1, max_features=None)\n\n'''\nYour code here: print the total english words in your input tokenizer and total chinese words in your output tokenizer below!\n'''","kernel":"nlp_env","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZzoUqCrq4fWj","outputId":"4290ee15-457e-44d7-f083-f12a2e5d78a2"},"output":{"0":{"data":{"text/plain":"'\\nYour code here: print the total english words in your input tokenizer and total chinese words in your output tokenizer below!\\n'"},"exec_count":7}},"pos":7,"start":1655237715553,"state":"done","type":"cell"}
{"cell_type":"code","end":1655237787593,"exec_count":11,"id":"e3908a","input":"'''\nYour code here: Explore this data. Can you calculate the maximum length of a sequence in each dataset english and chinese?\n'''\n# calculate max_len of any sequence in 'english' list and save it to a variable called max_english_length \nlen(english[1])\n# calculate max_len of any sequence in 'chinese' list and save it to a variable called max_chinese_length","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"14"},"exec_count":11}},"pos":6,"start":1655237787588,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"14aa69","input":"'''\nNo need to touch this code: \n'''\n\ndef translate(eng_sent, model, device):\n    # set up the inputs and variables\n    model.eval()\n    model.to(device)\n    eng_sent = tk.tokenize(eng_sent.lower()) + [\"<EOS>\"]\n    eng_sent = input_tokenizer.transform(eng_sent, max_len=in_maxlen, pad_first=False)\n    dec_in = ([\"<SOS>\"] + [\"<PAD>\"]*out_maxlen)[:out_maxlen]\n    dec_in = output_tokenizer.transform(dec_in, max_len=out_maxlen, pad_first=False)\n    \n    enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n    eng_sent, dec_in = torch.LongTensor(eng_sent), torch.LongTensor(dec_in)\n\n    eng_sent = eng_sent.unsqueeze(0)\n    dec_in = dec_in.unsqueeze(0)\n    eng_sent, dec_in = eng_sent.to(device), dec_in.to(device)\n\n    # run the model\n    with torch.no_grad():\n        # eng_sent: [1(b), 26(in_maxlen)]\n        embedded_X = model.embed_enc(eng_sent)\n        # embedded_X: [26(in_maxlen), 1(b), 64(d_model)] <- [1(b), 26(in_maxlen), 64(d_model)]\n        embedded_X = embedded_X.permute(1, 0, 2)\n        _, memory = model.encoder(embedded_X, enc_h_0)\n        pred_loc = 0\n        for i in range(out_maxlen-1):\n            embedded_Y = model.embed_dec(dec_in)\n            embedded_Y = embedded_Y.permute(1, 0, 2)\n            outputs, _ = model.decoder(embedded_Y, memory)\n            outputs = outputs.permute(1, 0, 2)\n            pred = model.fc(outputs)\n            pred = pred[0][pred_loc].topk(1)[1].item()\n            pred_loc += 1\n            if pred == 2:\n                dec_in[0][pred_loc] = pred\n                break\n            else:\n                dec_in[0][pred_loc] = pred\n    return dec_in","metadata":{"id":"XHs9IRJK8usV"},"pos":19,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"4e532c","input":"# Define Loss and Optimizer -- these are ways we define performance for our model. If you're curious: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\ncriterion = nn.CrossEntropyLoss()\noptim = torch.optim.Adam(model.parameters(), lr=1e-2)","metadata":{"id":"PtNvjmBo5A8W"},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"62d3e2","input":"showPlot([loss.cpu().item() for loss in loss_records])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":720},"id":"WGjbNIopCkzd","outputId":"dc2375cb-efe2-4756-dd01-309e4f056e1a"},"pos":17,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"655e17","input":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\n%matplotlib inline\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points): # Helper function for showing our plots\n    plt.figure()\n    fig, ax = plt.subplots()\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"id":"DCWlner5CkY-"},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6579f2","input":"'''\nYour code here: change the number of epochs to see how it effects training time and quality\n'''\nepochs = 200\n\n\n'''\nTraining -- no need to touch the code below.\n'''\ntorch.cuda.empty_cache()\nmodel.train()\nmodel.to(device)\nloss_records = []\n\n\nfor epoch in range(epochs):\n    # runs the model and calculates loss\n    loss = 0\n    for _, (enc_in, dec_in, dec_out) in enumerate(dataloader):\n        # enc_h_0.shape: [1(num_layers), 1(batch_size), 32(hidden_size)]\n        enc_h_0 = model.init_enc_hidden_GRU(batch_size, device)\n        # To Cuda Device if available\n        enc_in, dec_in = enc_in.to(device), dec_in.to(device)\n        \n        pred = model(enc_in, enc_h_0, dec_in)\n        \n        dec_out = dec_out.to(device)\n        for i in range(len(dec_out)): # dec_in.shape: [1(b), 40(out_maxlen)]\n            # pred[i].shape: [40(out_maxlen), 317(dec_n_class)]\n            # dec_out[i].shape: [40(out_maxlen)]\n            loss += criterion(pred[i], dec_out[i])\n\n    if (epoch) % 10 == 0:\n        print(f\"Epoch: {epoch}, Loss: {loss}\")\n\n    if (epoch) % 100 == 0:\n        loss_records.append(loss)\n    \n    # runs the actual back propacation\n    optim.zero_grad()\n    loss.backward()\n    optim.step()\n    torch.save(model.state_dict(), \"seq2seq.pt\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PTSlF8fk5QpG","outputId":"3eb0df28-80b9-452b-e9b5-5c7ffff27c98"},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6fa393","input":"'''\nYour code here: translate custom sentences using the code above. Hint: You won't need a for loop!\n'''","pos":23,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9005bd","input":"'''\nYour code here: Try printing some english and chinese sentences from their lists input_texts and target_texts!\n'''","pos":4,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"9ea302","input":"eng_maxlen = max_english_length + 1 # 25 + 1(<EOS> token)\nchin_maxlen = max_chinese_length + 1  # 39 + 1(<EOS> token or <SOS> token)\nbatch_size = 1 \n\n# Setup the Dataset.\ndataset = Dataset(\n    X = english,\n    Y = chinese,\n    in_tknz = input_tokenizer, out_tknz = output_tokenizer,\n    in_maxlen = eng_maxlen, out_maxlen = chin_maxlen\n)\n\n'''\nThe following are helper functions to help pytorch. You won't need to know this much.\n'''\n# NOTE: collate_fn preprocesses your input from PyTorch Dataset above during PyTorch DataLoader\ndef collate_fn(batch):\n    '''\n    param batch: ([enc_in, dec_in, dec_out]， [enc_in, dec_in, dec_out], output of getitem...)\n    '''\n    # unpack values\n    enc_in, dec_in, dec_out = list(zip(*batch))\n    # Return tensor type\n    return torch.LongTensor(enc_in), torch.LongTensor(dec_in), torch.LongTensor(dec_out)\n\ndef get_dataloader(dataset, batch_size, shuffle=True, drop_last=True, collate_fn=collate_fn):\n    '''\n    Returns a way to access and use the data\n    '''\n    dataloader = DataLoader(dataset=dataset,\n                            batch_size=batch_size,\n                            shuffle=shuffle,\n                            drop_last=drop_last,\n                            collate_fn=collate_fn)\n    return dataloader\n# Get PyTorch DataLoader\ndataloader = get_dataloader(dataset, batch_size)\ndataloader = get_dataloader(dataset, batch_size)","pos":10,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"ab426d","input":"model = Seq2Seq(\n    in_maxlen = in_maxlen,\n    out_maxlen = out_maxlen,\n    n_hidden = n_hidden,\n    enc_n_class = len(input_tokenizer.dict),\n    dec_n_class = len(output_tokenizer.dict),\n    d_model = d_model,\n    num_layers = 1,\n)\nmodel.to(device)\n# # If you have saved a model before\n# model.load_state_dict(torch.load(\"seq2seq.pt\", map_location=device))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVVbVP7l5AJg","outputId":"e28da9fa-5fa2-4fbd-b4d3-49de9999475b"},"pos":11,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"b8a622","input":"","pos":24,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"bd86f1","input":"import random\neng_sents = random.sample(input_texts, 5)\nfor sent in eng_sents:\n  translated = translate(sent, model, torch.device(\"cpu\"))\n  translated_sent = output_tokenizer.inverse_transform(translated[0], is_tensor=True)\n  translated_sent = \"\".join([word for word in translated_sent if word != \"<SOS>\" and word != \"<EOS>\"and word != \"<PAD>\"])\n  print(f\"{sent} -> \\n{translated_sent}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fh0-iZdvBUFF","outputId":"f42cb9ed-a961-4d0f-c94c-6be4fb8d6656"},"pos":21,"type":"cell"}
{"cell_type":"markdown","id":"123fa3","input":"## Preparing the data\nWe need to import our packages and data to learn a little bit about the problem at hand.","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"1ec2ff","input":"## Let's check out our model's progress\nNo need to change the code below, this will plot our loss over time. How do you think we can tweak our code to decrease loss even further?","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"21da59","input":"<h1>Training our model</h1>","metadata":{"id":"wVpmLnAtBLEV"},"pos":13,"type":"cell"}
{"cell_type":"markdown","id":"21fa13","input":"# The Task at Hand\n\nHave you ever wondered if computers could translate languages? Did you think google translate or duolingo worked because they memorized answers? \n\nThe type of problem that translation solves is sequence to sequence. For instance, we could convert an english input sequence to a german output sequence. \n\nIn this activity, we will create an english -> chinese translator and apply what we've been learning about LSTMs & RNNs.","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"25c911","input":"<h1>Code for Translating with our Model</h1>\nThis is where the Seq2Seq happens after the model is trained.\n","pos":18,"type":"cell"}
{"cell_type":"markdown","id":"af836a","input":"# Your turn!\nCan you use the code in the cell above to translate custom sentences? ","pos":22,"type":"cell"}
{"cell_type":"markdown","id":"b41d90","input":"<h1>Creating the model</h1>\n\n![image.png](data:image/png;base64,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)\n\nNOTE: For Structure of Encoder Inputs, they can all be either (assume all have same maxlen): \n\n1. \\<SOS>, word1, word2, word3, ..., \\<EOS>\n2. word1, word2, word3, ..., \\<EOS> \n3. word1, word2, word3, ...\n\nNOTE: But Decoder In and Out structures should always look like this (assume all have same maxlen):\n\n- Decoder Input: \\<SOS>, word1, word2, word3, ...\n- Decoder Output: word1, word2, word3, ..., \\<EOS>  \n\nThis means that our input and ouput max length should be one more than the sequence's max length.\n\nWHY? Data Structure:\n\n- 1. Encoder Input: [word1, word2, ... + <EOS>]\n- 2. Decoder Input: [<SOS> + word1, word2, ...]\n- 3. Decoder Output:[word1, word2, ... + <EOS>]\n    \n\nnn docs - https://pytorch.org/docs/stable/nn.html\n\n","pos":8,"type":"cell"}
{"cell_type":"markdown","id":"e23c35","input":"# Using our Model in Practice\nCheck out these examples below. This is how you can translate sequences!","metadata":{"id":"kG_fTQzoBsMu"},"pos":20,"type":"cell"}
{"id":0,"time":1655241520989,"type":"user"}
{"last_load":1655225094747,"type":"file"}