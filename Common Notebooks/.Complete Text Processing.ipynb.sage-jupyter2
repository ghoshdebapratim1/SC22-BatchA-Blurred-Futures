{"backend_state":"running","connection_file":"/projects/820ea3ac-497c-43fd-9cb7-abe34292faa8/.local/share/jupyter/runtime/kernel-51333954-2baf-4cff-8db0-5b0083949aa8.json","kernel":"nlp_env","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1655311967627,"exec_count":2,"id":"be178e","input":"import pandas as pd\nimport numpy as np\nimport spacy","kernel":"nlp_env","pos":3,"start":1655311964800,"state":"done","type":"cell"}
{"cell_type":"code","end":1655311969548,"exec_count":3,"id":"570eea","input":"from spacy.lang.en.stop_words import STOP_WORDS as stopwords","kernel":"nlp_env","pos":4,"start":1655311969536,"state":"done","type":"cell"}
{"cell_type":"code","end":1655311977642,"exec_count":4,"id":"9ed523","input":"df = pd.read_csv('https://raw.githubusercontent.com/laxmimerit/twitter-data/master/twitter4000.csv', encoding = 'latin1')","kernel":"nlp_env","pos":5,"start":1655311977322,"state":"done","type":"cell"}
{"cell_type":"code","end":1655311982159,"exec_count":5,"id":"b4383a","input":"df.head()","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>is bored and wants to watch a movie  any sugge...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>back in miami.  waiting to unboard ship</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@misskpey awwww dnt dis brng bak memoriessss, ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ughhh i am so tired  blahhhhhhhhh</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>@mandagoforth me bad! It's funny though. Zacha...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                              twitts  sentiment\n0  is bored and wants to watch a movie  any sugge...          0\n1           back in miami.  waiting to unboard ship           0\n2  @misskpey awwww dnt dis brng bak memoriessss, ...          0\n3                  ughhh i am so tired  blahhhhhhhhh          0\n4  @mandagoforth me bad! It's funny though. Zacha...          0"},"exec_count":5}},"pos":6,"start":1655311982107,"state":"done","type":"cell"}
{"cell_type":"code","end":1655311986034,"exec_count":6,"id":"5a3dd3","input":"df['sentiment'].value_counts()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"0    2000\n1    2000\nName: sentiment, dtype: int64"},"exec_count":6}},"pos":7,"start":1655311986017,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312037567,"exec_count":7,"id":"e2e5cb","input":"len('this is text'.split())","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"3"},"exec_count":7}},"pos":9,"start":1655312037545,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312050815,"exec_count":9,"id":"405b51","input":"df['word_counts'] = df['twitts'].apply(lambda x: len(str(x).split()))","kernel":"nlp_env","pos":10,"start":1655312050809,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312052970,"exec_count":10,"id":"5ce351","input":"df['word_counts'].max()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"32"},"exec_count":10}},"pos":12,"start":1655312052894,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312057030,"exec_count":11,"id":"04d502","input":"df['word_counts'].min()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"1"},"exec_count":11}},"pos":13,"start":1655312057011,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312061556,"exec_count":12,"id":"af994c","input":"df[df['word_counts']==1]","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>385</th>\n      <td>homework</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>691</th>\n      <td>@ekrelly</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1124</th>\n      <td>disappointed</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1286</th>\n      <td>@officialmgnfox</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1325</th>\n      <td>headache</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1897</th>\n      <td>@MCRmuffin</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2542</th>\n      <td>Graduated!</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2947</th>\n      <td>reading</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3176</th>\n      <td>@omeirdeleon</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3470</th>\n      <td>www.myspace.com/myfinalthought</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3966</th>\n      <td>@gethyp3</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                               twitts  sentiment  word_counts\n385                         homework           0            1\n691                         @ekrelly           0            1\n1124                    disappointed           0            1\n1286                 @officialmgnfox           0            1\n1325                        headache           0            1\n1897                      @MCRmuffin           0            1\n2542                      Graduated!           1            1\n2947                         reading           1            1\n3176                    @omeirdeleon           1            1\n3470  www.myspace.com/myfinalthought           1            1\n3966                        @gethyp3           1            1"},"exec_count":12}},"pos":14,"start":1655312061536,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312080329,"exec_count":13,"id":"ff362c","input":"len('this is')","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"7"},"exec_count":13}},"pos":16,"start":1655312080300,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312082368,"exec_count":14,"id":"998b9e","input":"def char_counts(x):\n    s = x.split()\n    x = ''.join(s)\n    return len(x)","kernel":"nlp_env","pos":17,"start":1655312082353,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312084831,"exec_count":15,"id":"c9de8f","input":"char_counts('this is')","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"6"},"exec_count":15}},"pos":18,"start":1655312084809,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312293064,"exec_count":18,"id":"ea2d78","input":"df['char_counts'] = df['twitts'].apply(lambda x: char_counts(str(x)))","kernel":"nlp_env","pos":19,"start":1655312293052,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312295881,"exec_count":19,"id":"d976d6","input":"df.sample(5)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>661</th>\n      <td>is wondering why when David finally comes to E...</td>\n      <td>0</td>\n      <td>19</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>3110</th>\n      <td>@sugarbritchesyo he did, he got 3 wisdom teeth...</td>\n      <td>1</td>\n      <td>16</td>\n      <td>81</td>\n    </tr>\n    <tr>\n      <th>3687</th>\n      <td>Pool side! Feels like old times</td>\n      <td>1</td>\n      <td>6</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1276</th>\n      <td>@icaruswingz  The cunt.</td>\n      <td>0</td>\n      <td>3</td>\n      <td>20</td>\n    </tr>\n    <tr>\n      <th>78</th>\n      <td>has used more moisturer today than all the oth...</td>\n      <td>0</td>\n      <td>17</td>\n      <td>93</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n661   is wondering why when David finally comes to E...          0   \n3110  @sugarbritchesyo he did, he got 3 wisdom teeth...          1   \n3687                   Pool side! Feels like old times           1   \n1276                            @icaruswingz  The cunt.          0   \n78    has used more moisturer today than all the oth...          0   \n\n      word_counts  char_counts  \n661            19           83  \n3110           16           81  \n3687            6           26  \n1276            3           20  \n78             17           93  "},"exec_count":19}},"pos":20,"start":1655312295819,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312303478,"exec_count":20,"id":"56f2e6","input":"x = 'this is' # 6/2 = 3\ny = 'thankyou guys' # 12/2 = 6","kernel":"nlp_env","pos":22,"start":1655312303461,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312309285,"exec_count":21,"id":"bfbbbd","input":"df['avg_word_len'] = df['char_counts']/df['word_counts']","kernel":"nlp_env","pos":23,"start":1655312309280,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312316793,"exec_count":22,"id":"32dff7","input":"len(stopwords)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"326"},"exec_count":22}},"pos":27,"start":1655312316778,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312319431,"exec_count":23,"id":"84b850","input":"x = 'this is the text data'","kernel":"nlp_env","pos":28,"start":1655312319406,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312504438,"exec_count":24,"id":"b93c74","input":"x = 'this is 1 and 2'","kernel":"nlp_env","pos":47,"start":1655312504423,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312507393,"exec_count":25,"id":"989836","input":"x.split()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"['this', 'is', '1', 'and', '2']"},"exec_count":25}},"pos":48,"start":1655312507261,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312509646,"exec_count":26,"id":"c0c706","input":"x.split()[3].isdigit()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"False"},"exec_count":26}},"pos":49,"start":1655312509629,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312515407,"exec_count":27,"id":"e39a3f","input":"[t for t in x.split() if t.isdigit()]","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"['1', '2']"},"exec_count":27}},"pos":50,"start":1655312515389,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312518066,"exec_count":28,"id":"99c616","input":"df['numerics_count'] = df['twitts'].apply(lambda x: len([t for t in x.split() if t.isdigit()]))","kernel":"nlp_env","pos":51,"start":1655312518038,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312525561,"exec_count":29,"id":"3ec1bd","input":"df.sample(5)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2670</th>\n      <td>@Stev02008 he's still only about 6 months old,...</td>\n      <td>1</td>\n      <td>27</td>\n      <td>109</td>\n      <td>4.037037</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3672</th>\n      <td>@jirehd Do you watch Daisy of Love??</td>\n      <td>1</td>\n      <td>7</td>\n      <td>30</td>\n      <td>4.285714</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3435</th>\n      <td>@FabbiB: I'm looking forward to the birthday s...</td>\n      <td>1</td>\n      <td>20</td>\n      <td>89</td>\n      <td>4.450000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1600</th>\n      <td>@llauraxxx I REGRET IT   Haha i cant get over ...</td>\n      <td>0</td>\n      <td>21</td>\n      <td>91</td>\n      <td>4.333333</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>327</th>\n      <td>@BridgetsBeaches  dont get it here in australi...</td>\n      <td>0</td>\n      <td>21</td>\n      <td>82</td>\n      <td>3.904762</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n2670  @Stev02008 he's still only about 6 months old,...          1   \n3672              @jirehd Do you watch Daisy of Love??           1   \n3435  @FabbiB: I'm looking forward to the birthday s...          1   \n1600  @llauraxxx I REGRET IT   Haha i cant get over ...          0   \n327   @BridgetsBeaches  dont get it here in australi...          0   \n\n      word_counts  char_counts  avg_word_len  numerics_count  \n2670           27          109      4.037037               1  \n3672            7           30      4.285714               0  \n3435           20           89      4.450000               0  \n1600           21           91      4.333333               0  \n327            21           82      3.904762               0  "},"exec_count":29}},"pos":52,"start":1655312525510,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312535565,"exec_count":30,"id":"99daa5","input":"[t for t in x.split() if t.isupper()]","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"[]"},"exec_count":30}},"pos":55,"start":1655312535546,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312538492,"exec_count":31,"id":"bb39df","input":"df['upper_counts'] = df['twitts'].apply(lambda x: len([t for t in x.split() if t.isupper()]))","kernel":"nlp_env","pos":56,"start":1655312538470,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312548753,"exec_count":32,"id":"e3f788","input":"x = 'this is Text'","kernel":"nlp_env","pos":63,"start":1655312548732,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312552247,"exec_count":33,"id":"3f21e3","input":"x.lower()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'this is text'"},"exec_count":33}},"pos":64,"start":1655312552231,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312554599,"exec_count":34,"id":"0aa168","input":"x = 45.0\nstr(x).lower()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'45.0'"},"exec_count":34}},"pos":65,"start":1655312554558,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312558687,"exec_count":35,"id":"70cdad","input":"df['twitts'] = df['twitts'].apply(lambda x: str(x).lower())","kernel":"nlp_env","pos":66,"start":1655312558682,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312598970,"exec_count":36,"id":"6e3e59","input":"contractions = { \n\"ain't\": \"am not\",\n\"aren't\": \"are not\",\n\"can't\": \"cannot\",\n\"can't've\": \"cannot have\",\n\"'cause\": \"because\",\n\"could've\": \"could have\",\n\"couldn't\": \"could not\",\n\"couldn't've\": \"could not have\",\n\"didn't\": \"did not\",\n\"doesn't\": \"does not\",\n\"don't\": \"do not\",\n\"hadn't\": \"had not\",\n\"hadn't've\": \"had not have\",\n\"hasn't\": \"has not\",\n\"haven't\": \"have not\",\n\"he'd\": \"he would\",\n\"he'd've\": \"he would have\",\n\"he'll\": \"he will\",\n\"he'll've\": \"he will have\",\n\"he's\": \"he is\",\n\"how'd\": \"how did\",\n\"how'd'y\": \"how do you\",\n\"how'll\": \"how will\",\n\"how's\": \"how does\",\n\"i'd\": \"i would\",\n\"i'd've\": \"i would have\",\n\"i'll\": \"i will\",\n\"i'll've\": \"i will have\",\n\"i'm\": \"i am\",\n\"i've\": \"i have\",\n\"isn't\": \"is not\",\n\"it'd\": \"it would\",\n\"it'd've\": \"it would have\",\n\"it'll\": \"it will\",\n\"it'll've\": \"it will have\",\n\"it's\": \"it is\",\n\"let's\": \"let us\",\n\"ma'am\": \"madam\",\n\"mayn't\": \"may not\",\n\"might've\": \"might have\",\n\"mightn't\": \"might not\",\n\"mightn't've\": \"might not have\",\n\"must've\": \"must have\",\n\"mustn't\": \"must not\",\n\"mustn't've\": \"must not have\",\n\"needn't\": \"need not\",\n\"needn't've\": \"need not have\",\n\"o'clock\": \"of the clock\",\n\"oughtn't\": \"ought not\",\n\"oughtn't've\": \"ought not have\",\n\"shan't\": \"shall not\",\n\"sha'n't\": \"shall not\",\n\"shan't've\": \"shall not have\",\n\"she'd\": \"she would\",\n\"she'd've\": \"she would have\",\n\"she'll\": \"she will\",\n\"she'll've\": \"she will have\",\n\"she's\": \"she is\",\n\"should've\": \"should have\",\n\"shouldn't\": \"should not\",\n\"shouldn't've\": \"should not have\",\n\"so've\": \"so have\",\n\"so's\": \"so is\",\n\"that'd\": \"that would\",\n\"that'd've\": \"that would have\",\n\"that's\": \"that is\",\n\"there'd\": \"there would\",\n\"there'd've\": \"there would have\",\n\"there's\": \"there is\",\n\"they'd\": \"they would\",\n\"they'd've\": \"they would have\",\n\"they'll\": \"they will\",\n\"they'll've\": \"they will have\",\n\"they're\": \"they are\",\n\"they've\": \"they have\",\n\"to've\": \"to have\",\n\"wasn't\": \"was not\",\n\" u \": \" you \",\n\" ur \": \" your \",\n\" n \": \" and \",\n\"won't\": \"would not\",\n'dis': 'this',\n'bak': 'back',\n'brng': 'bring'}","kernel":"nlp_env","pos":69,"start":1655312598946,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312615494,"exec_count":37,"id":"d6b653","input":"def cont_to_exp(x):\n    if type(x) is str:\n        for key in contractions:\n            value = contractions[key]\n            x = x.replace(key, value)\n        return x\n    else:\n        return x\n    ","kernel":"nlp_env","pos":71,"start":1655312615477,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312625025,"exec_count":39,"id":"52469c","input":"x = \"i'm don't he'll\" # \"i am do not he will\"","kernel":"nlp_env","pos":70,"start":1655312625008,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312627261,"exec_count":40,"id":"fd3e97","input":"cont_to_exp(x)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'i am do not he will'"},"exec_count":40}},"pos":72,"start":1655312627241,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312641482,"exec_count":41,"id":"1cbe76","input":"%%timeit\ndf['twitts'] = df['twitts'].apply(lambda x: cont_to_exp(x))","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"60.3 ms ± 2.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"}},"pos":73,"start":1655312636435,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312672470,"exec_count":42,"id":"5ddccf","input":"df.sample(5)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2586</th>\n      <td>@sam_sms that sounds like a very nice life you...</td>\n      <td>1</td>\n      <td>27</td>\n      <td>111</td>\n      <td>4.111111</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1405</th>\n      <td>i just went to google something then forgot wh...</td>\n      <td>0</td>\n      <td>16</td>\n      <td>62</td>\n      <td>3.875000</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3083</th>\n      <td>@kayleenduhh morning  ily &amp;lt;3 i am still on ...</td>\n      <td>1</td>\n      <td>12</td>\n      <td>56</td>\n      <td>4.666667</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3344</th>\n      <td>i looooove ace of cakes! catching up on it at ...</td>\n      <td>1</td>\n      <td>11</td>\n      <td>40</td>\n      <td>3.636364</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1835</th>\n      <td>@ellievontainted i know i love true bloods</td>\n      <td>0</td>\n      <td>7</td>\n      <td>36</td>\n      <td>5.142857</td>\n      <td>0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n2586  @sam_sms that sounds like a very nice life you...          1   \n1405  i just went to google something then forgot wh...          0   \n3083  @kayleenduhh morning  ily &lt;3 i am still on ...          1   \n3344  i looooove ace of cakes! catching up on it at ...          1   \n1835        @ellievontainted i know i love true bloods           0   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \n2586           27          111      4.111111               0             1  \n1405           16           62      3.875000               0             2  \n3083           12           56      4.666667               0             0  \n3344           11           40      3.636364               0             1  \n1835            7           36      5.142857               0             6  "},"exec_count":42}},"pos":74,"start":1655312672438,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312677649,"exec_count":43,"id":"af5f2d","input":"import re","kernel":"nlp_env","pos":77,"start":1655312677622,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312680647,"exec_count":44,"id":"30fa9e","input":"df[df['twitts'].str.contains('hotmail.com')]","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3713</th>\n      <td>@securerecs arghh me please  markbradbury_16@h...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>51</td>\n      <td>10.2</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n3713  @securerecs arghh me please  markbradbury_16@h...          1   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \n3713            5           51          10.2               0             0  "},"exec_count":44}},"pos":78,"start":1655312680623,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312722199,"exec_count":46,"id":"73043d","input":"df.iloc[3713]['twitts']","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'@securerecs arghh me please  markbradbury_16@hotmail.com'"},"exec_count":46}},"pos":79,"start":1655312722170,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312733960,"exec_count":47,"id":"64da5a","input":"x = '@securerecs arghh me please  markbradbury_16@hotmail.com'","kernel":"nlp_env","pos":80,"start":1655312733954,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312738977,"exec_count":48,"id":"aa725a","input":"re.findall(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)', x)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"['markbradbury_16@hotmail.com']"},"exec_count":48}},"pos":81,"start":1655312738954,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312749771,"exec_count":49,"id":"cd11c0","input":"df['emails'] = df['twitts'].apply(lambda x: re.findall(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+\\b)', x))","kernel":"nlp_env","pos":82,"start":1655312749705,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312755557,"exec_count":50,"id":"e56c17","input":"df['emails_count'] = df['emails'].apply(lambda x: len(x))","kernel":"nlp_env","pos":83,"start":1655312755538,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312758204,"exec_count":51,"id":"a72d8e","input":"df[df['emails_count']>0]","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3713</th>\n      <td>@securerecs arghh me please  markbradbury_16@h...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>51</td>\n      <td>10.2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[markbradbury_16@hotmail.com]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n3713  @securerecs arghh me please  markbradbury_16@h...          1   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \\\n3713            5           51          10.2               0             0   \n\n                             emails  emails_count  \n3713  [markbradbury_16@hotmail.com]             1  "},"exec_count":51}},"pos":84,"start":1655312758130,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312770995,"exec_count":52,"id":"3ff284","input":"re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", x)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'@securerecs arghh me please  '"},"exec_count":52}},"pos":85,"start":1655312770958,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312786654,"exec_count":53,"id":"d55315","input":"df['twitts'] = df['twitts'].apply(lambda x: re.sub(r'([a-z0-9+._-]+@[a-z0-9+._-]+\\.[a-z0-9+_-]+)',\"\", x))","kernel":"nlp_env","pos":86,"start":1655312786622,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312789668,"exec_count":54,"id":"b37c24","input":"df[df['emails_count']>0]","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3713</th>\n      <td>@securerecs arghh me please</td>\n      <td>1</td>\n      <td>5</td>\n      <td>51</td>\n      <td>10.2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[markbradbury_16@hotmail.com]</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                             twitts  sentiment  word_counts  char_counts  \\\n3713  @securerecs arghh me please            1            5           51   \n\n      avg_word_len  numerics_count  upper_counts  \\\n3713          10.2               0             0   \n\n                             emails  emails_count  \n3713  [markbradbury_16@hotmail.com]             1  "},"exec_count":54}},"pos":87,"start":1655312789606,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312841121,"exec_count":55,"id":"c1e1c1","input":"x = 'hi, thanks to watching it. for more visit https://youtube.com/kgptalkie'","kernel":"nlp_env","pos":90,"start":1655312841106,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312847021,"exec_count":56,"id":"d48f91","input":"re.findall(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', x)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"[('https', 'youtube.com', '/kgptalkie')]"},"exec_count":56}},"pos":92,"start":1655312846977,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312851052,"exec_count":57,"id":"176bb7","input":"df['url_flags'] = df['twitts'].apply(lambda x: len(re.findall(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', x)))","kernel":"nlp_env","pos":93,"start":1655312851035,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312853636,"exec_count":58,"id":"56d456","input":"df[df['url_flags']>0].sample(5)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n      <th>url_flags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>183</th>\n      <td>photo: miss germany  http://tumblr.com/xf825f012</td>\n      <td>0</td>\n      <td>4</td>\n      <td>44</td>\n      <td>11.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3582</th>\n      <td>eating at the beach side at watie beach cafe. ...</td>\n      <td>1</td>\n      <td>19</td>\n      <td>109</td>\n      <td>5.736842</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1916</th>\n      <td>http://twitpic.com/68n0t - waffle - this recip...</td>\n      <td>0</td>\n      <td>9</td>\n      <td>51</td>\n      <td>5.666667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3268</th>\n      <td>http://twitpic.com/696p8 2 of the kiddies who ...</td>\n      <td>1</td>\n      <td>11</td>\n      <td>57</td>\n      <td>5.181818</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>704</th>\n      <td>@x_imanerd_x http://twitpic.com/7y752 - you ca...</td>\n      <td>0</td>\n      <td>9</td>\n      <td>57</td>\n      <td>6.333333</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n183    photo: miss germany  http://tumblr.com/xf825f012          0   \n3582  eating at the beach side at watie beach cafe. ...          1   \n1916  http://twitpic.com/68n0t - waffle - this recip...          0   \n3268  http://twitpic.com/696p8 2 of the kiddies who ...          1   \n704   @x_imanerd_x http://twitpic.com/7y752 - you ca...          0   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \\\n183             4           44     11.000000               0             0   \n3582           19          109      5.736842               0             1   \n1916            9           51      5.666667               0             0   \n3268           11           57      5.181818               1             0   \n704             9           57      6.333333               0             0   \n\n     emails  emails_count  url_flags  \n183      []             0          1  \n3582     []             0          1  \n1916     []             0          1  \n3268     []             0          1  \n704      []             0          1  "},"exec_count":58}},"pos":94,"start":1655312853611,"state":"done","type":"cell"}
{"cell_type":"code","end":1655312943499,"exec_count":59,"id":"148ba5","input":"df[df['twitts'].str.contains('rt')]","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n      <th>url_flags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>@mandagoforth me bad! it is funny though. zach...</td>\n      <td>0</td>\n      <td>26</td>\n      <td>116</td>\n      <td>4.461538</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ut oh, i wonder if the ram on the desktop is s...</td>\n      <td>0</td>\n      <td>14</td>\n      <td>46</td>\n      <td>3.285714</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>@paulmccourt dunno what sky you're looking at!...</td>\n      <td>0</td>\n      <td>15</td>\n      <td>80</td>\n      <td>5.333333</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>im back home in belfast  im realli tired thoug...</td>\n      <td>0</td>\n      <td>22</td>\n      <td>84</td>\n      <td>3.818182</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>@lilmonkee987 i know what you mean... i feel s...</td>\n      <td>0</td>\n      <td>11</td>\n      <td>48</td>\n      <td>4.363636</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3913</th>\n      <td>for the press so after she recovered she kille...</td>\n      <td>1</td>\n      <td>24</td>\n      <td>100</td>\n      <td>4.166667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3919</th>\n      <td>earned her cpr &amp;amp; first aid certifications!</td>\n      <td>1</td>\n      <td>7</td>\n      <td>40</td>\n      <td>5.714286</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3945</th>\n      <td>@teciav &amp;quot;i look high, i look low, i look ...</td>\n      <td>1</td>\n      <td>23</td>\n      <td>106</td>\n      <td>4.608696</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3951</th>\n      <td>i am soo very parched. and hungry. oh and i am...</td>\n      <td>1</td>\n      <td>21</td>\n      <td>87</td>\n      <td>4.142857</td>\n      <td>2</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3986</th>\n      <td>@countroshculla yeah..needed to get up early.....</td>\n      <td>1</td>\n      <td>10</td>\n      <td>69</td>\n      <td>6.900000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>382 rows × 10 columns</p>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n4     @mandagoforth me bad! it is funny though. zach...          0   \n23    ut oh, i wonder if the ram on the desktop is s...          0   \n59    @paulmccourt dunno what sky you're looking at!...          0   \n75    im back home in belfast  im realli tired thoug...          0   \n81    @lilmonkee987 i know what you mean... i feel s...          0   \n...                                                 ...        ...   \n3913  for the press so after she recovered she kille...          1   \n3919    earned her cpr &amp; first aid certifications!           1   \n3945  @teciav &quot;i look high, i look low, i look ...          1   \n3951  i am soo very parched. and hungry. oh and i am...          1   \n3986  @countroshculla yeah..needed to get up early.....          1   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \\\n4              26          116      4.461538               0             0   \n23             14           46      3.285714               0             2   \n59             15           80      5.333333               0             0   \n75             22           84      3.818182               0             1   \n81             11           48      4.363636               0             0   \n...           ...          ...           ...             ...           ...   \n3913           24          100      4.166667               0             0   \n3919            7           40      5.714286               0             1   \n3945           23          106      4.608696               0             0   \n3951           21           87      4.142857               2             1   \n3986           10           69      6.900000               0             0   \n\n     emails  emails_count  url_flags  \n4        []             0          0  \n23       []             0          0  \n59       []             0          0  \n75       []             0          0  \n81       []             0          0  \n...     ...           ...        ...  \n3913     []             0          0  \n3919     []             0          0  \n3945     []             0          0  \n3951     []             0          0  \n3986     []             0          0  \n\n[382 rows x 10 columns]"},"exec_count":59}},"pos":101,"start":1655312943417,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313226021,"exec_count":66,"id":"e327c4","input":"x = '[removed] @username: hello hirt'","kernel":"nlp_env","pos":102,"start":1655313225991,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313235760,"exec_count":67,"id":"ee6668","input":"re.sub(r'\\bremoved\\b', '', x).strip()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'[] @username: hello hirt'"},"exec_count":67}},"pos":103,"start":1655313235733,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313254853,"exec_count":68,"id":"55672a","input":"df['twitts'] = df['twitts'].apply(lambda x: re.sub(r'\\bremoved\\b', '', x).strip())","kernel":"nlp_env","pos":104,"start":1655313254793,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313273839,"exec_count":69,"id":"491782","input":"df.sample(3)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n      <th>url_flags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>590</th>\n      <td>i am reminded how much i hate summer heat  hea...</td>\n      <td>0</td>\n      <td>12</td>\n      <td>48</td>\n      <td>4.000000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3919</th>\n      <td>earned her cpr &amp;amp; first aid certifications!</td>\n      <td>1</td>\n      <td>7</td>\n      <td>40</td>\n      <td>5.714286</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1691</th>\n      <td>@bowl_the_bunny it does. i do not even get exc...</td>\n      <td>0</td>\n      <td>26</td>\n      <td>106</td>\n      <td>4.076923</td>\n      <td>0</td>\n      <td>4</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n590   i am reminded how much i hate summer heat  hea...          0   \n3919     earned her cpr &amp; first aid certifications!          1   \n1691  @bowl_the_bunny it does. i do not even get exc...          0   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \\\n590            12           48      4.000000               0             2   \n3919            7           40      5.714286               0             1   \n1691           26          106      4.076923               0             4   \n\n     emails  emails_count  url_flags  \n590      []             0          0  \n3919     []             0          0  \n1691     []             0          0  "},"exec_count":69}},"pos":109,"start":1655313273809,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313279307,"exec_count":70,"id":"407eec","input":"x = '@duyku apparently i was not ready enough... i...'","kernel":"nlp_env","pos":110,"start":1655313279272,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313282094,"exec_count":71,"id":"22c9cd","input":"re.sub(r'[^\\w ]+', \"\", x)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'duyku apparently i was not ready enough i'"},"exec_count":71}},"pos":111,"start":1655313282079,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313298667,"exec_count":72,"id":"7cf595","input":"df['twitts'] = df['twitts'].apply(lambda x: re.sub(r'[^\\w ]+', \"\", x))","kernel":"nlp_env","pos":112,"start":1655313298644,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313301514,"exec_count":73,"id":"b49afe","input":"df.sample(5)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n      <th>url_flags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1215</th>\n      <td>on train home  train full and lots of drunk me...</td>\n      <td>0</td>\n      <td>19</td>\n      <td>74</td>\n      <td>3.894737</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>657</th>\n      <td>i need a bf lol anyone wanna sign up haha the ...</td>\n      <td>0</td>\n      <td>32</td>\n      <td>105</td>\n      <td>3.281250</td>\n      <td>0</td>\n      <td>4</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3900</th>\n      <td>rtroth let me know whenwhere you open your tea...</td>\n      <td>1</td>\n      <td>10</td>\n      <td>46</td>\n      <td>4.600000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2569</th>\n      <td>just listened to old voice comments on my snap...</td>\n      <td>1</td>\n      <td>16</td>\n      <td>73</td>\n      <td>4.562500</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>401</th>\n      <td>morning my throat is still sore definitely get...</td>\n      <td>0</td>\n      <td>22</td>\n      <td>113</td>\n      <td>5.136364</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n1215  on train home  train full and lots of drunk me...          0   \n657   i need a bf lol anyone wanna sign up haha the ...          0   \n3900  rtroth let me know whenwhere you open your tea...          1   \n2569  just listened to old voice comments on my snap...          1   \n401   morning my throat is still sore definitely get...          0   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \\\n1215           19           74      3.894737               0             0   \n657            32          105      3.281250               0             4   \n3900           10           46      4.600000               0             0   \n2569           16           73      4.562500               0             1   \n401            22          113      5.136364               0             0   \n\n     emails  emails_count  url_flags  \n1215     []             0          0  \n657      []             0          0  \n3900     []             0          0  \n2569     []             0          0  \n401      []             0          0  "},"exec_count":73}},"pos":113,"start":1655313301496,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313307360,"exec_count":74,"id":"99ca43","input":"x =  'hi    hello     how are you'","kernel":"nlp_env","pos":116,"start":1655313307341,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313310176,"exec_count":75,"id":"997d53","input":"' '.join(x.split())","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'hi hello how are you'"},"exec_count":75}},"pos":117,"start":1655313310172,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313312926,"exec_count":76,"id":"2964f8","input":"df['twitts'] = df['twitts'].apply(lambda x: ' '.join(x.split()))","kernel":"nlp_env","pos":118,"start":1655313312889,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313319032,"exec_count":77,"id":"c5aa76","input":"from bs4 import BeautifulSoup","kernel":"nlp_env","pos":122,"start":1655313318939,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313321511,"exec_count":78,"id":"0ac072","input":"x = '<html><h1> thanks for watching it </h1></html>'","kernel":"nlp_env","pos":123,"start":1655313321480,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313327054,"exec_count":79,"id":"a3a07f","input":"x.replace('<html><h1>', '').replace('</h1></html>', '') #not rec","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"' thanks for watching it '"},"exec_count":79}},"pos":124,"start":1655313327035,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313536487,"exec_count":84,"id":"2c20c7","input":"BeautifulSoup(x, 'html.parser').get_text().strip()","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'thanks for watching it'"},"exec_count":84}},"pos":125,"start":1655313536455,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313555889,"exec_count":85,"id":"93b9ce","input":"%%time\ndf['twitts'] = df['twitts'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text().strip())","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"CPU times: user 267 ms, sys: 1.22 ms, total: 269 ms\nWall time: 281 ms\n"}},"pos":126,"start":1655313555595,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313561748,"exec_count":86,"id":"e8c62e","input":"x = 'Áccěntěd těxt'","kernel":"nlp_env","pos":129,"start":1655313561729,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313564467,"exec_count":87,"id":"477070","input":"import unicodedata","kernel":"nlp_env","pos":130,"start":1655313564451,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313570978,"exec_count":88,"id":"84bf96","input":"def remove_accented_chars(x):\n    x = unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n    return x","kernel":"nlp_env","pos":131,"start":1655313570973,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313574878,"exec_count":89,"id":"ea061e","input":"remove_accented_chars(x)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'Accented text'"},"exec_count":89}},"pos":132,"start":1655313574862,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313579303,"exec_count":90,"id":"494740","input":"df['twitts'] = df['twitts'].apply(lambda x: remove_accented_chars(x))","kernel":"nlp_env","pos":133,"start":1655313579261,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313619881,"exec_count":91,"id":"5f7118","input":"x = 'this is this okay bye'","kernel":"nlp_env","pos":155,"start":1655313619861,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313626062,"exec_count":92,"id":"c30082","input":"text = ' '.join(df['twitts'])","kernel":"nlp_env","pos":156,"start":1655313626038,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313628273,"exec_count":93,"id":"56eea0","input":"len(text)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"284633"},"exec_count":93}},"pos":157,"start":1655313628255,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313630697,"exec_count":94,"id":"59efe0","input":"text = text.split()","kernel":"nlp_env","pos":158,"start":1655313630647,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313632935,"exec_count":95,"id":"4b2634","input":"len(text)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"53667"},"exec_count":95}},"pos":159,"start":1655313632912,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313647108,"exec_count":96,"id":"510509","input":"freq_comm = pd.Series(text).value_counts()","kernel":"nlp_env","pos":160,"start":1655313647083,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313654087,"exec_count":97,"id":"8d7695","input":"f20 = freq_comm[:20]","kernel":"nlp_env","pos":161,"start":1655313654067,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313656029,"exec_count":98,"id":"92d1cc","input":"f20","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"i       2392\nto      1363\nthe     1299\na        957\nis       877\nmy       825\nyou      822\nit       735\nand      733\nnot      599\nin       571\nfor      521\nof       482\nam       472\nthat     435\nme       432\non       427\nhave     419\nso       373\nat       320\ndtype: int64"},"exec_count":98}},"pos":162,"start":1655313655964,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313665793,"exec_count":99,"id":"8ab561","input":"df['twitts'] = df['twitts'].apply(lambda x: ' '.join([t for t in x.split() if t not in f20]))","kernel":"nlp_env","pos":163,"start":1655313665729,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313668253,"exec_count":100,"id":"02c2a4","input":"df.sample(5)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n      <th>url_flags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3571</th>\n      <td>bobbythomas1 methinks get up earlier sorry mis...</td>\n      <td>1</td>\n      <td>20</td>\n      <td>90</td>\n      <td>4.500000</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2431</th>\n      <td>dannygokey aww well least got some sleep liked...</td>\n      <td>1</td>\n      <td>22</td>\n      <td>92</td>\n      <td>4.181818</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>650</th>\n      <td>jovanh yep tweeting while driving too</td>\n      <td>0</td>\n      <td>6</td>\n      <td>34</td>\n      <td>5.666667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3780</th>\n      <td>ooh_its_allyson yeaa imaa record xd or jazmine...</td>\n      <td>1</td>\n      <td>22</td>\n      <td>85</td>\n      <td>3.863636</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>anthothemantho hahaha agree cried like baby wh...</td>\n      <td>0</td>\n      <td>16</td>\n      <td>71</td>\n      <td>4.437500</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n3571  bobbythomas1 methinks get up earlier sorry mis...          1   \n2431  dannygokey aww well least got some sleep liked...          1   \n650               jovanh yep tweeting while driving too          0   \n3780  ooh_its_allyson yeaa imaa record xd or jazmine...          1   \n66    anthothemantho hahaha agree cried like baby wh...          0   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \\\n3571           20           90      4.500000               0             2   \n2431           22           92      4.181818               0             2   \n650             6           34      5.666667               0             0   \n3780           22           85      3.863636               0             2   \n66             16           71      4.437500               0             0   \n\n     emails  emails_count  url_flags  \n3571     []             0          0  \n2431     []             0          0  \n650      []             0          0  \n3780     []             0          0  \n66       []             0          0  "},"exec_count":100}},"pos":164,"start":1655313668230,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313677865,"exec_count":101,"id":"75224f","input":"rare20 = freq_comm.tail(20)","kernel":"nlp_env","pos":167,"start":1655313677849,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313708897,"exec_count":103,"id":"d42b27","input":"df['twitts'] = df['twitts'].apply(lambda x: ' '.join([t for t in x.split() if t not in rare20]))","kernel":"nlp_env","pos":168,"start":1655313708850,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313715665,"exec_count":104,"id":"881885","input":"df.sample(5)","kernel":"nlp_env","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>twitts</th>\n      <th>sentiment</th>\n      <th>word_counts</th>\n      <th>char_counts</th>\n      <th>avg_word_len</th>\n      <th>numerics_count</th>\n      <th>upper_counts</th>\n      <th>emails</th>\n      <th>emails_count</th>\n      <th>url_flags</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3770</th>\n      <td>watching stardust love this movie</td>\n      <td>1</td>\n      <td>6</td>\n      <td>31</td>\n      <td>5.166667</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1533</th>\n      <td>lovin her lululemon shortsmaybe should start g...</td>\n      <td>0</td>\n      <td>19</td>\n      <td>88</td>\n      <td>4.631579</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2281</th>\n      <td>shame can hear parents talking about smirks an...</td>\n      <td>1</td>\n      <td>21</td>\n      <td>101</td>\n      <td>4.809524</td>\n      <td>0</td>\n      <td>0</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3074</th>\n      <td>spending lot more time twitter after installin...</td>\n      <td>1</td>\n      <td>21</td>\n      <td>100</td>\n      <td>4.761905</td>\n      <td>0</td>\n      <td>1</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2308</th>\n      <td>graceawong lmao if kitchen had been cool then ...</td>\n      <td>1</td>\n      <td>24</td>\n      <td>112</td>\n      <td>4.666667</td>\n      <td>0</td>\n      <td>2</td>\n      <td>[]</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                 twitts  sentiment  \\\n3770                  watching stardust love this movie          1   \n1533  lovin her lululemon shortsmaybe should start g...          0   \n2281  shame can hear parents talking about smirks an...          1   \n3074  spending lot more time twitter after installin...          1   \n2308  graceawong lmao if kitchen had been cool then ...          1   \n\n      word_counts  char_counts  avg_word_len  numerics_count  upper_counts  \\\n3770            6           31      5.166667               0             0   \n1533           19           88      4.631579               0             2   \n2281           21          101      4.809524               0             0   \n3074           21          100      4.761905               0             1   \n2308           24          112      4.666667               0             2   \n\n     emails  emails_count  url_flags  \n3770     []             0          0  \n1533     []             0          0  \n2281     []             0          0  \n3074     []             0          0  \n2308     []             0          0  "},"exec_count":104}},"pos":169,"start":1655313715644,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313736398,"exec_count":105,"id":"8f84d0","input":"from wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n%matplotlib inline","kernel":"nlp_env","pos":172,"start":1655313735547,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313738621,"exec_count":106,"id":"1764c7","input":"text = ' '.join(df['twitts'])","kernel":"nlp_env","pos":173,"start":1655313738611,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313740757,"exec_count":107,"id":"5a531f","input":"len(text)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"236970"},"exec_count":107}},"pos":174,"start":1655313740747,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313744437,"exec_count":108,"id":"f98ef7","input":"wc = WordCloud(width=800, height=400).generate(text)\nplt.imshow(wc)\nplt.axis('off')\nplt.show()","kernel":"nlp_env","output":{"0":{"data":{"image/png":"c7aafab4fef02a96a69115d25f9c02adfab69b7d","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"needs_background":"light"}}},"pos":175,"start":1655313743046,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313772929,"exec_count":109,"id":"c340ed","input":"!python -m textblob.download_corpora","kernel":"nlp_env","output":{"0":{"name":"stdout","text":"/usr/bin/python: No module named textblob\r\n"}},"pos":179,"start":1655313772169,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313791700,"exec_count":110,"id":"58a14e","input":"from textblob import TextBlob","kernel":"nlp_env","pos":180,"start":1655313791008,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313832899,"exec_count":115,"id":"ce60ad","input":"x = 'thanks#watching this video. please like it'","kernel":"nlp_env","pos":185,"start":1655313832890,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313834937,"exec_count":116,"id":"408f6a","input":"TextBlob(x).words","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"WordList(['thanks', 'watching', 'this', 'video', 'please', 'like', 'it'])"},"exec_count":116}},"pos":186,"start":1655313834918,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313837211,"exec_count":117,"id":"fe7be5","input":"doc = nlp(x)\nfor token in doc:\n    print(token)","kernel":"nlp_env","output":{"0":{"ename":"NameError","evalue":"name 'nlp' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [117]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m(x)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token)\n","\u001b[0;31mNameError\u001b[0m: name 'nlp' is not defined"]}},"pos":187,"start":1655313837057,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313852946,"exec_count":119,"id":"6ea7f5","input":"x","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'thanks#watching this video. please like it'"},"exec_count":119}},"pos":196,"start":1655313852930,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313858533,"exec_count":121,"id":"851c7d","input":"tb.detect_language()","kernel":"nlp_env","output":{"0":{"ename":"HTTPError","evalue":"HTTP Error 400: Bad Request","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_language\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/blob.py:597\u001b[0m, in \u001b[0;36mBaseBlob.detect_language\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;124;03m\"\"\"Detect the blob's language using the Google Translate API.\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \n\u001b[1;32m    574\u001b[0m \u001b[38;5;124;03mRequires an internet connection.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m:rtype: str\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    592\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTextBlob.detext_translate is deprecated and will be removed in a future release. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse the official Google Translate API instead.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m\n\u001b[1;32m    596\u001b[0m )\n\u001b[0;32m--> 597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/translate.py:76\u001b[0m, in \u001b[0;36mTranslator.detect\u001b[0;34m(self, source, host, type_)\u001b[0m\n\u001b[1;32m     70\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m: source}\n\u001b[1;32m     71\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{url}\u001b[39;00m\u001b[38;5;124m&sl=auto&tk=\u001b[39m\u001b[38;5;132;01m{tk}\u001b[39;00m\u001b[38;5;124m&client=\u001b[39m\u001b[38;5;132;01m{client}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     72\u001b[0m     url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl,\n\u001b[1;32m     73\u001b[0m     tk\u001b[38;5;241m=\u001b[39m_calculate_tk(source),\n\u001b[1;32m     74\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     75\u001b[0m )\n\u001b[0;32m---> 76\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m result, language \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response)\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m language\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/translate.py:96\u001b[0m, in \u001b[0;36mTranslator._request\u001b[0;34m(self, url, host, type_, data)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m host \u001b[38;5;129;01mor\u001b[39;00m type_:\n\u001b[1;32m     95\u001b[0m     req\u001b[38;5;241m.\u001b[39mset_proxy(host\u001b[38;5;241m=\u001b[39mhost, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mtype_)\n\u001b[0;32m---> 96\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m content \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/urllib/request.py:214\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    213\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 214\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/urllib/request.py:523\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    522\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 523\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m~/miniconda3/lib/python3.9/urllib/request.py:632\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m~/miniconda3/lib/python3.9/urllib/request.py:561\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    560\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/urllib/request.py:494\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    493\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 494\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m~/miniconda3/lib/python3.9/urllib/request.py:641\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 400: Bad Request"]}},"pos":198,"start":1655313857624,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313871623,"exec_count":122,"id":"ba0949","input":"tb.translate(to = 'zh')","kernel":"nlp_env","output":{"0":{"ename":"AttributeError","evalue":"'list' object has no attribute 'strip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Input \u001b[0;32mIn [122]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/blob.py:568\u001b[0m, in \u001b[0;36mBaseBlob.translate\u001b[0;34m(self, from_lang, to)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Translate the blob to another language.\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mUses the Google Translate API. Returns a new TextBlob.\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m:rtype: :class:`BaseBlob <BaseBlob>`\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    563\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTextBlob.translate is deprecated and will be removed in a future release. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse the official Google Translate API instead.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m\n\u001b[1;32m    567\u001b[0m )\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfrom_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_lang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_lang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m)\u001b[49m)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/translate.py:61\u001b[0m, in \u001b[0;36mTranslator.translate\u001b[0;34m(self, source, from_lang, to_lang, host, type_)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_translation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/translate.py:88\u001b[0m, in \u001b[0;36mTranslator._validate_translation\u001b[0;34m(self, source, result)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m PY2:\n\u001b[1;32m     87\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m() \u001b[38;5;241m==\u001b[39m source\u001b[38;5;241m.\u001b[39mstrip():\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotTranslated(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranslation API returned the input string unchanged.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"]}},"pos":199,"start":1655313870554,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313976754,"exec_count":124,"id":"6d34ea","input":"x = 'thankks forr waching it'","kernel":"nlp_env","pos":181,"start":1655313976747,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313978479,"exec_count":125,"id":"9ac323","input":"x = TextBlob(x).correct()","kernel":"nlp_env","pos":182,"start":1655313978433,"state":"done","type":"cell"}
{"cell_type":"code","end":1655313979706,"exec_count":126,"id":"de04df","input":"str(x)","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"'thanks for watching it'"},"exec_count":126}},"pos":183,"start":1655313979686,"state":"done","type":"cell"}
{"cell_type":"code","id":"003af2","input":"#shh://git@git.com:username/repo.git=riif?%","pos":91,"state":"done","type":"cell"}
{"cell_type":"code","id":"01c70d","input":"tb = TextBlob(x, analyzer=NaiveBayesAnalyzer())","pos":204,"state":"done","type":"cell"}
{"cell_type":"code","id":"024594","input":"df.sample(5)","pos":67,"state":"done","type":"cell"}
{"cell_type":"code","id":"039777","input":"df['stop_words_len'] = df['twitts'].apply(lambda x: len([t for t in x.split() if t in stopwords]))","pos":32,"state":"done","type":"cell"}
{"cell_type":"code","id":"03d4e1","input":"","pos":127,"state":"done","type":"cell"}
{"cell_type":"code","id":"0a8682","input":"tb.sentiment","pos":205,"state":"done","type":"cell"}
{"cell_type":"code","id":"0bc0ce","input":"x.split()","pos":39,"state":"done","type":"cell"}
{"cell_type":"code","id":"0e7981","input":"[t for t in x.split() if t.startswith('@')]","pos":40,"state":"done","type":"cell"}
{"cell_type":"code","id":"0f468a","input":"","pos":216,"state":"done","type":"cell"}
{"cell_type":"code","id":"118aa5","input":"","pos":165,"state":"done","type":"cell"}
{"cell_type":"code","id":"15d65d","input":"for noun in doc.noun_chunks:\n    print(noun)","pos":192,"state":"done","type":"cell"}
{"cell_type":"code","id":"17eef4","input":"x","pos":95,"state":"done","type":"cell"}
{"cell_type":"code","id":"18df22","input":"print(stopwords)","pos":26,"state":"done","type":"cell"}
{"cell_type":"code","id":"1b2979","input":"df.sample(5)","pos":141,"state":"done","type":"cell"}
{"cell_type":"code","id":"1bbfb6","input":"","pos":208,"state":"done","type":"cell"}
{"cell_type":"code","id":"1cb6cc","input":"def make_to_base(x):\n    x = str(x)\n    x_list = []\n    doc = nlp(x)\n    \n    for token in doc:\n        lemma = token.lemma_\n        if lemma == '-PRON-' or lemma == 'be':\n            lemma = token.text\n\n        x_list.append(lemma)\n    return ' '.join(x_list)","pos":149,"state":"done","type":"cell"}
{"cell_type":"code","id":"1f4133","input":"","pos":107,"state":"done","type":"cell"}
{"cell_type":"code","id":"201412","input":"","pos":119,"state":"done","type":"cell"}
{"cell_type":"code","id":"21a61c","input":"df['twitts_no_stop'] = df['twitts'].apply(lambda x: ' '.join([t for t in x.split() if t not in stopwords]))","pos":140,"state":"done","type":"cell"}
{"cell_type":"code","id":"24d27b","input":"","pos":217,"state":"done","type":"cell"}
{"cell_type":"code","id":"252fc9","input":"","pos":134,"state":"done","type":"cell"}
{"cell_type":"code","id":"259396","input":"","pos":142,"state":"done","type":"cell"}
{"cell_type":"code","id":"2e872b","input":"","pos":35,"state":"done","type":"cell"}
{"cell_type":"code","id":"304834","input":"df.sample(5)","pos":11,"state":"done","type":"cell"}
{"cell_type":"code","id":"3318b7","input":"from textblob.sentiments import NaiveBayesAnalyzer","pos":202,"state":"done","type":"cell"}
{"cell_type":"code","id":"33538c","input":"","pos":114,"state":"done","type":"cell"}
{"cell_type":"code","id":"37ec49","input":"!pip install lxml","pos":121,"state":"done","type":"cell"}
{"cell_type":"code","id":"381e61","input":"df.sample(5)","pos":33,"state":"done","type":"cell"}
{"cell_type":"code","id":"401cb5","input":"","pos":145,"state":"done","type":"cell"}
{"cell_type":"code","id":"4024a5","input":"df['twitts'] = df['twitts'].apply(lambda x: make_to_base(x))","pos":151,"state":"done","type":"cell"}
{"cell_type":"code","id":"412359","input":"x = 'Breaking News: Donal Trump, the president of the USA is looking to sign a deal to mine the moon'","pos":190,"state":"done","type":"cell"}
{"cell_type":"code","id":"48d0ec","input":"","pos":153,"state":"done","type":"cell"}
{"cell_type":"code","id":"4f2471","input":"len([t for t in x.split() if t in stopwords])","pos":31,"state":"done","type":"cell"}
{"cell_type":"code","id":"51417e","input":"x = 'this is chocolates. what is times? this balls'","pos":148,"state":"done","type":"cell"}
{"cell_type":"code","id":"54c429","input":"re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , x)","pos":96,"state":"done","type":"cell"}
{"cell_type":"code","id":"554727","input":"","pos":176,"state":"done","type":"cell"}
{"cell_type":"code","id":"59e532","input":"","pos":144,"state":"done","type":"cell"}
{"cell_type":"code","id":"5a82f1","input":"","pos":59,"state":"done","type":"cell"}
{"cell_type":"code","id":"5f24cc","input":"x = 'this is a stop words'","pos":138,"state":"done","type":"cell"}
{"cell_type":"code","id":"6265f5","input":"","pos":88,"state":"done","type":"cell"}
{"cell_type":"code","id":"639af1","input":"x = 'we all stands together. we are gonna win this fight'","pos":203,"state":"done","type":"cell"}
{"cell_type":"code","id":"655ffd","input":"","pos":60,"state":"done","type":"cell"}
{"cell_type":"code","id":"66d49e","input":"","pos":106,"state":"done","type":"cell"}
{"cell_type":"code","id":"6ce48c","input":"df.sample(4)","pos":24,"state":"done","type":"cell"}
{"cell_type":"code","id":"6d79a0","input":"","pos":188,"state":"done","type":"cell"}
{"cell_type":"code","id":"719e2d","input":"","pos":212,"state":"done","type":"cell"}
{"cell_type":"code","id":"78dd8c","input":"df['twitts'] = df['twitts'].apply(lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , x))","pos":97,"state":"done","type":"cell"}
{"cell_type":"code","id":"7a98d0","input":"","pos":105,"state":"done","type":"cell"}
{"cell_type":"code","id":"7e4d44","input":"!pip install -U textblob","pos":178,"state":"done","type":"cell"}
{"cell_type":"code","id":"8b2c6a","input":"","pos":75,"state":"done","type":"cell"}
{"cell_type":"code","id":"8c9aae","input":"# !pip install wordcloud","pos":171,"state":"done","type":"cell"}
{"cell_type":"code","id":"96b248","input":"","pos":210,"state":"done","type":"cell"}
{"cell_type":"code","id":"9a5b44","input":"","pos":211,"state":"done","type":"cell"}
{"cell_type":"code","id":"9b55b4","input":"nlp = spacy.load('en_core_web_sm')","pos":147,"state":"done","type":"cell"}
{"cell_type":"code","id":"a08009","input":"","pos":193,"state":"done","type":"cell"}
{"cell_type":"code","id":"a0a025","input":"","pos":136,"state":"done","type":"cell"}
{"cell_type":"code","id":"a83421","input":"[t for t in x.split() if t in stopwords]","pos":30,"state":"done","type":"cell"}
{"cell_type":"code","id":"a8c4f5","input":"df['mentions_count'] = df['twitts'].apply(lambda x: len([t for t in x.split() if t.startswith('@')]))","pos":43,"state":"done","type":"cell"}
{"cell_type":"code","id":"a9cc60","input":"","pos":215,"state":"done","type":"cell"}
{"cell_type":"code","id":"ada5be","input":"df['hashtags_count'] = df['twitts'].apply(lambda x: len([t for t in x.split() if t.startswith('#')]))","pos":42,"state":"done","type":"cell"}
{"cell_type":"code","id":"b3ce09","input":"","pos":143,"state":"done","type":"cell"}
{"cell_type":"code","id":"b430e9","input":"df.sample(5)","pos":98,"state":"done","type":"cell"}
{"cell_type":"code","id":"b51302","input":"' '.join([t for t in x.split() if t not in stopwords])","pos":139,"state":"done","type":"cell"}
{"cell_type":"code","id":"b568ad","input":"df.sample(5)","pos":152,"state":"done","type":"cell"}
{"cell_type":"code","id":"c0977c","input":"","pos":99,"state":"done","type":"cell"}
{"cell_type":"code","id":"c337a9","input":"doc = nlp(x)","pos":191,"state":"done","type":"cell"}
{"cell_type":"code","id":"c56ba2","input":"","pos":200,"state":"done","type":"cell"}
{"cell_type":"code","id":"ce7093","input":"","pos":207,"state":"done","type":"cell"}
{"cell_type":"code","id":"d1de27","input":"len([t for t in x.split() if t.startswith('@')])","pos":41,"state":"done","type":"cell"}
{"cell_type":"code","id":"d74204","input":"df.sample(5)","pos":57,"state":"done","type":"cell"}
{"cell_type":"code","id":"da1f5b","input":"df.sample(5)","pos":44,"state":"done","type":"cell"}
{"cell_type":"code","id":"daf255","input":"","pos":209,"state":"done","type":"cell"}
{"cell_type":"code","id":"db3f0e","input":"","pos":135,"state":"done","type":"cell"}
{"cell_type":"code","id":"dca0f7","input":"","pos":213,"state":"done","type":"cell"}
{"cell_type":"code","id":"dd6039","input":"x = 'I AM HAPPY'\ny = 'i am happy'","pos":54,"state":"done","type":"cell"}
{"cell_type":"code","id":"e85751","input":"","pos":36,"state":"done","type":"cell"}
{"cell_type":"code","id":"e934b7","input":"x = 'this is #hashtag and this is @mention'","pos":38,"state":"done","type":"cell"}
{"cell_type":"code","id":"f23b45","input":"","pos":34,"state":"done","type":"cell"}
{"cell_type":"code","id":"f51086","input":"","pos":206,"state":"done","type":"cell"}
{"cell_type":"code","id":"f8764c","input":"x.split()","pos":29,"state":"done","type":"cell"}
{"cell_type":"code","id":"fa7fe0","input":"make_to_base(x)","pos":150,"state":"done","type":"cell"}
{"cell_type":"code","id":"fd2b96","input":"","pos":214,"state":"done","type":"cell"}
{"cell_type":"code","id":"fe2113","input":"df.iloc[3962]['twitts']","pos":58,"state":"done","type":"cell"}
{"cell_type":"code","id":"ff92ad","input":"","pos":45,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"00eeb6","input":"## Remove RT ","pos":100,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"01b95e","input":"## Count and Remove Emails ","pos":76,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"0e17c2","input":"### Preprocessing and Cleaning\n- Lower case\n- Contraction to Expansion\n- Emails removal and counts\n- URLs removal and counts\n- Removal of RT\n- Removal of Special Characters\n- Removal of multiple spaces\n- Removal of HTML tags\n- Removal of accented characters\n- Removal of Stop Words\n- Conversion into base form of words\n- Common Occuring words Removal\n- Rare Occuring words Removal\n- Word Cloud\n- Spelling Correction\n- Tokenization\n- Lemmatization\n- Detecting Entities using NER\n- Noun Detection\n- Language Detection\n- Sentence Translation\n- Using Inbuilt Sentiment Classifier","pos":2,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"0ee12b","input":"## Lower Case Conversion ","pos":62,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"1bf125","input":"## Use TextBlob's Inbuilt Sentiment Classifier ","pos":201,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"393fd8","input":"## Count URLs and Remove it ","pos":89,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3b4e77","input":"## Complete Text Processing ","pos":0,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3c9a50","input":"## Word Counts","pos":8,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"3df2ac","input":"## Remove multiple spaces `\"hi   hello    \"`","pos":115,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"538880","input":"## Special Chars removal or punctuation removal ","pos":108,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"643215","input":"## If numeric digits are present in twitts","pos":46,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"67a74b","input":"## Remove Accented Chars ","pos":128,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"77a63c","input":"## Remove HTML tags","pos":120,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"7fc3c6","input":"## Contraction to Expansion ","pos":68,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"804e71","input":"## Count #HashTags and @Mentions ","pos":37,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"8e9217","input":"## UPPER case words count ","pos":53,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9a4b91","input":"## Stop Words Count ","pos":25,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"9e5096","input":"# Preprocessing and Cleaning","pos":61,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a1e3c0","input":"## Average Word Length","pos":21,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"a42083","input":"## Remove Stop Words ","pos":137,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"aa9dd2","input":"Language Code: https://www.loc.gov/standards/iso639-2/php/code_list.php","pos":195,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"afd71e","input":"### General Feature Extraction\n\n- File loading\n- Word counts\n- Characters count\n- Average characters per word\n- Stop words count\n- Count #HashTags and @Mentions\n- If numeric digits are present in twitts\n- Upper case word counts\n\n","pos":1,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"b4bc9e","input":"## Convert into base or root form of word ","pos":146,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"bf5e34","input":"## Common words removal ","pos":154,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"ccba0a","input":"## Language Translation and Detection","pos":194,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d1592b","input":"# Characters Count","pos":15,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"d99171","input":"## Word Cloud Visualization ","pos":170,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e030bb","input":"## Tokenization using TextBlob\n","pos":184,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"e32f71","input":"## Detecting Nouns ","pos":189,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f59ad8","input":"## Spelling Correction ","pos":177,"state":"done","type":"cell"}
{"cell_type":"markdown","id":"f5b387","input":"## Rare words removal ","pos":166,"state":"done","type":"cell"}
{"end":1655313526525,"exec_count":83,"id":"190dc1","input":"soup =  BeautifulSoup(x,  \"html.parser\")","kernel":"nlp_env","pos":124.5,"start":1655313526490,"state":"done","type":"cell"}
{"end":1655313696298,"exec_count":102,"id":"5cc09e","input":"rare20","kernel":"nlp_env","output":{"0":{"data":{"text/plain":"children               1\nwsendoutscuds          1\nhttptwitpiccom6uvgi    1\ncreamm                 1\nabc                    1\ngreekshow              1\nkai                    1\nmeriah                 1\nyg                     1\nsambutannya            1\nmakasih                1\npermit                 1\nharizadri              1\nmets                   1\nbelive                 1\nvoodoo                 1\npitching               1\nalexs                  1\nlbbchat                1\nrerunlovin             1\ndtype: int64"},"exec_count":102}},"pos":167.5,"start":1655313696290,"state":"done","type":"cell"}
{"end":1655314526233,"exec_count":127,"id":"eb3650","input":"df['twitts']=df['twitts'].apply(lambda x:str(TextBlob(x).correct()))","kernel":"nlp_env","output":{"0":{"ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwitts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtwitts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n","Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwitts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtwitts\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:\u001b[38;5;28mstr\u001b[39m(\u001b[43mTextBlob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/blob.py:609\u001b[0m, in \u001b[0;36mBaseBlob.correct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    607\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mregexp_tokenize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+|[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    608\u001b[0m corrected \u001b[38;5;241m=\u001b[39m (Word(w)\u001b[38;5;241m.\u001b[39mcorrect() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens)\n\u001b[0;32m--> 609\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(ret)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/blob.py:608\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;66;03m# regex matches: word or punctuation or whitespace\u001b[39;00m\n\u001b[1;32m    607\u001b[0m tokens \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mtokenize\u001b[38;5;241m.\u001b[39mregexp_tokenize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+|[^\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms]|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 608\u001b[0m corrected \u001b[38;5;241m=\u001b[39m (\u001b[43mWord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m tokens)\n\u001b[1;32m    609\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(corrected)\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(ret)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/blob.py:142\u001b[0m, in \u001b[0;36mWord.correct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorrect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;124;03m'''Correct the spelling of the word. Returns the word with the highest\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m    confidence using the spelling corrector.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Word(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspellcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/blob.py:134\u001b[0m, in \u001b[0;36mWord.spellcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspellcheck\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;124;03m'''Return a list of (word, confidence) tuples of spelling corrections.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Based on: Peter Norvig, \"How to Write a Spelling Corrector\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.6.0\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/en/__init__.py:123\u001b[0m, in \u001b[0;36msuggest\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msuggest\u001b[39m(w):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;124;03m\"\"\" Returns a list of (word, confidence)-tuples of spelling corrections.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspelling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/_text.py:1399\u001b[0m, in \u001b[0;36mSpelling.suggest\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39misdigit():\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [(w, \u001b[38;5;241m1.0\u001b[39m)] \u001b[38;5;66;03m# 1.5\u001b[39;00m\n\u001b[1;32m   1397\u001b[0m candidates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known([w]) \\\n\u001b[1;32m   1398\u001b[0m           \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edit1(w)) \\\n\u001b[0;32m-> 1399\u001b[0m           \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edit2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m) \\\n\u001b[1;32m   1400\u001b[0m           \u001b[38;5;129;01mor\u001b[39;00m [w]\n\u001b[1;32m   1401\u001b[0m candidates \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(c, \u001b[38;5;241m0.0\u001b[39m), c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m candidates]\n\u001b[1;32m   1402\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28msum\u001b[39m(p \u001b[38;5;28;01mfor\u001b[39;00m p, word \u001b[38;5;129;01min\u001b[39;00m candidates) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/_text.py:1376\u001b[0m, in \u001b[0;36mSpelling._edit2\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;124;03m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[0;32m-> 1376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edit1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_edit1\u001b[49m\u001b[43m(\u001b[49m\u001b[43me1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/_text.py:1376\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;124;03m\"\"\" Returns a set of words with edit distance 2 from the given word\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Only keep candidates that are actually known words (20% speedup).\u001b[39;00m\n\u001b[0;32m-> 1376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mset\u001b[39m(e2 \u001b[38;5;28;01mfor\u001b[39;00m e1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edit1(w) \u001b[38;5;28;01mfor\u001b[39;00m e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_edit1(e1) \u001b[38;5;28;01mif\u001b[39;00m \u001b[43me2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m)\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/_text.py:96\u001b[0m, in \u001b[0;36mlazydict.__contains__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__contains__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m__contains__\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/textblob/_text.py:87\u001b[0m, in \u001b[0;36mlazydict._lazy\u001b[0;34m(self, method, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, types\u001b[38;5;241m.\u001b[39mMethodType(\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mdict\u001b[39m, method), \u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}},"pos":183.5,"start":1655314215220,"state":"done","type":"cell"}
{"id":0,"time":1655311902798,"type":"user"}
{"last_load":1655311903308,"type":"file"}